# Story 09 하이퍼스레딩 : 병렬성의 극대화
하이퍼스레딩
* 하나의 물리 프로세서가 두 개의 논리 프로세서로 보이게 하는 기술
* 슈퍼스칼라 프로세서에서 동시에 두 스레드로부터 명령어를 가져와 파이프라인에 넣는 기술
* 이렇게 하면 제대로 활용되지 않은 프로세서 자원을 더 효율적으로 운용 가능

두 개 이상의 논리 프로세서를 보이게 하는 원리
* 스레드 문맥을 하드웨어 수준에서 복제하기 때문

## 하이퍼스레딩이 뭐야?
하이퍼스레딩(Hyper-Threading)
* 인텔이 펜티엄 4에 구현한 동시 멀티스레딩(Simultaneous Multi-Threading, SMT) 기술의 상품명
* 물리 프로세서 코어는 하나인데 두 개의 논리 프로세서(logical processor)로 보이게 하는 기술
* 하드웨어 수준에서 두 개 이상의 스레드가 동시 실행 -> 하드웨어 스레드라는 표현 사용
* 두 개 이상의 논리 프로세서도 동시 멀티스레딩 기술로 만들 수 있다.

물리적으로 하나의 프로세서에서 논리적으로 여러 개가 보일 수 있는 원인
* 스레드 문맥(context)를 하드웨어가 동시에 여러 개를 지원할 수 있기 때문

하드웨어 멀티스레딩
* 동시 멀티스레딩 기술의 근본
* 여러 개의 스레드 문맥을 동시에 하드웨어가 관리하면서 여러 스레드를 실행시키는 기술

멀티태스킹 - 현대 운영체제는 모두 지원
* 일반적인 싱글코어 프로세서 -> 오직 하나의 스레드만 처리 가능
* 프로세서 자원을 여러 스레드에 돌아가면서 빌려주는 스레드 스케줄링이 필요

문맥 교환(context switching)
* 한 스레드가 자신에게 주어진 시간만큼 프로세서를 썼다면 운영체제가 이 스레드에서 프로세서를 빼앗아 다른 스레드에게 주는 것
* 이 때 문맥 교환을 구현하려면 명시적으로 이전 문맥을 저장
  * 비용이 발생한다.
* 무작정 스레드를 많이 만들면 문맥 교환 비용으로 결코 높은 성능을 얻을 수 없다.

문맥 교환 비용을 하드웨어가 어떻게 줄일 수 있을까?
* 여기서 말하는 문맥 : 컴퓨터 구조적 상태(architectural state)
* 쉽게 말해 스레드가 수행 중인 레지스터 값
* Win32 API 중 GetThreadContext라는 스레드의 문맥을 얻는 함수가 있음

GetThreadContext가 채워주는 CONTEXT 구조체
~~~C++
typedef struct _CONTEXT
{
... 생략
    DWORD ContextFlags;
    FLOATING_SAVE_AREA FloatSave;

    // This section is specified/returned if the ContextFlags word contians the flag CONTEXT_SEGMENTS.
    DWORD SegGs, SegFs, SegEs, SegDs;

    // This section is specified/returned if the ContextFlags word contians the flag CONTEXT_INTEGER.
    DWORD Edi, Esi, Ebx, Edx, Ecx, Eax;

    // This section is specified/returned if the ContextFlags word contians the flag CONTEXT_CONTROL.
    DWORD Ebp, Eip, SegCs, EFlags, Esp;

... 생략
} CONTEXT;
~~~
* 결국 스레드 문맥의 핵심은 레지스터 집합
* 레지스터 값은 문맥 교환할 때 메모리로 잠시 쫓겨 났다가 다시 복구
* 하드웨어 멀티스레딩은 스레드 문맥을 유지하는 레지스터를 복제하여 동시에 여러 스레드 문맥을 유지
  * 문맥 교환 비용이 거의 들지 않으면서 여러 스레드를 처리할 수 있다.

멀티스레딩이 효과적인 더 근본적인 이유
* 스레드 수준 병렬성(TLP) : 스레드 간 뮤텍스(mutex)나 임계영역(critical section)을 이용해 여러 스레드는 완벽하게 독립적(병렬)으로 실행될 수 있다.
* 즉, 하드웨어 멀티스레딩은 TLP를 최대한 활용하는 방법

멀티스레딩은 자원의 효율성을 극대화하는 기술
* 에너지 효율 또한 높일 수 있다.
* 비순차 실행이 순차 실행보다 더 나은 성능을 보이는 이유
  * 낭비되는 사이클을 줄일 수 있어서
  * 그러나 이것도 완벽하지는 않다.

3-와이드 슈퍼스칼라 프로세서의 모습

![9-01](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/7dad0996-76a1-40f3-a4f3-81e000cb76e9)
* x로 표시된 상자는 일을 하지 않는 이슈 슬롯(issue slot)
  * 이슈 슬롯 : 파이프라인에 명령어를 넣을 수 있는 입구
* 즉, x는 주어진 시간에 투입할 명령어가 없어 낭비되었다는 것
* 여러 제약 때문에 3개보다 적은 명령어를 넣을 때가 많을 수 있다.
* 어떤 사이클은 명령어를 하나도 넣을 수 없을 수 있다. - 수직 방향의 낭비
  * 임계 경로(critical path)에 있는 명령어가 캐시 미스를 겪고, 이때 찾을 수 있는 ILP가 없다면 완전히 놀게 됨

멀티스레딩 기술은 이런 낭비를 줄일 수 있다.
* 특히 수직 방향의 낭비를 크게 줄인다.
* 이 공간에 다른 스레드의 명령어를 가져와 넣는 것
* 즉, 하드웨어 멀티스레딩은 프로세서가 하나보다 많은 스레드 문맥을 관리하며 실행하는 것을 가리킴
  * 문맥 교환 비용도 줄이고, 노는 자원에 TLP를 얻어 적극적으로 사용하는 기법

멀티스레딩은 구현 방식에 따라 몇 가지로 나뉜다.
* 여러 스레드로부터 명령어를 어떻게 읽을 것인가에 따라 구분
  * 미세 단위(Fine-Grained) 멀티스레딩
  * 큰 단위(Coarse-Grained) 멀티스레딩
  * 동시(Simultaneous) 멀티스레딩

### 미세 단위 멀티스레딩
* 운영체제의 비선점(Preemptive) 스케줄링 기법과 흡사
* 일장 사이클 동안 번갈아가며 프로세서가 스레드로부터 명령어를 가져와 파이프라인에 넣는다.
* 가장 미세하게 만든다면 사이클마다 프로세서는 하드웨어 스레드를 돌아가며 명령어를 가져와 실행한다.

미세 단위 멀티스레딩 적용 그림

![9-02](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/780cc5f1-a643-459e-b31d-e18b9dda0a96)
* 사이클마다 다른 스레드 A와 B로부터 명령어를 인출
* 하드웨어 멀티스레딩은 수직 방향 낭비를 줄인다.
* 그럼에도 A, B에서 어떤 사이클에 투입할 수 있는 명령어가 하나도 없다면 낭비는 계속 일어난다.

### 큰 단위 멀티스레딩

![9-03](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/dd1157e7-2960-41e0-9e6c-6864491e990d)

* 큰 단위는 정의에 따라 여러 가지가 될 수 있다.
  * 하나가 아닌 여러 개의 사이클을 단위로 하여 스케줄링할 수도 있다.
* 사이클 단위보다 어떤 스레드에서 이벤트(캐시 미스 등)이 발생하여 명령어를 투입할 수 없을 때 문맥을 다른 스레드로 전환하는 것이 일반적인 방식의 구현
* 역시 운영체제의 스케줄링이 단순히 하드웨어에서 구현되는 것으로 볼 수 있다.
  * 대신 문맥 비용의 비용이 거의 없다.
* 레이턴시가 긴 명령어가 걸렸을 때 스케줄링이 일어난다해 Switch-On-Event 멀티태스킹이라고도 한다.

### 동시 멀티스레딩
* 지금까지의 미세/큰 단위 멀티스레딩은 수평 방향의 낭비는 줄이지 못했다.
* 동시 멀티스레딩에서는 이 문제를 해결 가능하다.

![9-04](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/c7e286f0-9328-459a-aefa-bf84de1bd66b)
* 동시 멀티스레딩은 멀티스레딩 기술의 극단적인 형태
* 매 사이클마다 여러 스레드에서 '동시에' 명령어를 가져와 파이프라인에 넣는다.
* 수평 방향의 낭비를 다른 스레드에서 가져와서 채운다.
* 물론 수평/수직 방향의 낭비를 완전히 제거할 수 있는 것은 아니다.

처음으로 동시 멀티스레딩을 제안한 논문
* 8-와이드 슈퍼스칼라 순차 방식의 프로세서에서 19%의 자원만이 바쁘게 사용
  * 나머지 자원은 캐시미스, TLB 미스, 메모리 로드 지연 시간, 명령어 의존성 등으로 낭비
  * 결국 프로세서 자원이 여러 시스템 내 이벤트로 인해 제대로 활용되지 못했다.
  * 원인이 제각각 다르므로 단순한 개선책으로는 이 낭비를 크게 줄일 수 없었다는 결론.
* 이에 대한 해결책으로 동시 멀티스레딩을 제시

인텔이 구현한 하이퍼스레딩
* 하나의 물리 코어를 두 개의 논리 프로세서로 보이게 한다.
  * 2-way SMT
* N-way SMT도 가능하다. 또한 비순차/순차에 상관없이 구현될 수 있다.
  * Sun의 UltraSPARC 2는 SMT와 비슷한 개념의 CMT를 탑재하여 8-way 멀티스레딩까지 지원

## 동시 멀티스레딩의 구현과 성능
동시 멀티스레딩은 1995년 워싱턴 주립대학에서 최초로 제안한 기술
* 대학 마이크로아키텍처 논문이 프로세서로 구현되기에는 어려운 점이 많다.
  * 시뮬레이터의 오차
  * 대학에서는 세부적인 구현 문제를 거론하기 힘듬
* 좋은 논문의 조건
  * 아이디어가 얼마나 중요한 문제가 해결하는가?
  * 해결법이 과거 방식보다 참신한가?
* 그런데 얼마나 자세히 구현했는가는 중요하지 않다.
* 따라서 실제 프로세서에 구현되기에는 많은 난관

동시 멀티스레딩은 대학교에서 제안한 아이디어가 비교적 빠른 시일 내 구현되어 출시된 좋은 예
* 1999년 컴팩 컴퓨터 소속이었던 알파 프로세서 EV8에서 처음으로 구현이 시도됨
* EV8은 8개의 명령어를 처리할 수 있는 슈퍼스칼라 프로세서에 4-웨이 동시 멀티스레딩을 지원하는 구조
* 알파 프로세서의 설계 인력이 2001년에 인텔로 매각되며 동시 멀티스레딩은 인텔 펜티엄 4에서 하이퍼스레딩이라는 이름으로 구현

### 동시 멀티스레딩이 매력적인 이유
하드웨어 부담이 크지 않으며, 동시에 여러 하드웨어 스레드 문맥을 유지할 수 있다는 점
* EV8의 4-way 멀티스레딩을 구현
  * 6%의 면적만 더 필요
* 인텔의 펜티엄 4 하이퍼스레딩 구현
  * 5%의 면적만 더 필요
* 면적이 적다 - 적은 전력만이 더 필요함

비순차 프로세서에서 가장 중요한 명령어 스케줄링 장치와 실행 장치가 SMT에 거의 무관하다는 것
* 전면적인 파이프라인 수정 없이 노는 자원을 써 논리 프로세서 개수를 늘릴 수 있다.

SMT 구현의 구분
* 복제, 분할(parition), 공유, 무관

네할렘의 SMT 구현 정책

![9-05](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/bc23c0ed-dfe9-4edc-804b-dfff0df7f443)

* 중요한 레지스터 파일은 복제
* 일부 자원은 정적으로 분할

인텔이 주장하는 자료에 따르면 하이퍼스레딩을 Core i7에 적용했을 때
* 최대 34%까지 성능 향상

그러나 하이퍼스레딩은 늘 좋은 성능을 가져다주는 건 아니다.
* 주요 자원은 대부분 공유된다.
* 이에 따라 좋지 않은 영향을 주는 실행 조합이 반드시 있다.
* 그래서 펜티엄 4에서 사용되었던 하이퍼스레딩은 다음 코어 아키텍처에는 적용되지 않았다.

동시 멀티스레딩 환경에서 캐시와 비순차 실행 장치를 공유함에 따라 불균형이 야기될 수 있다.
* 여러 스레드에서 명령어를 인출해야 하는데 어떤 규칙과 정책으로 뽑아낼지 결정하기 어렵다.
* 어떤 식으로 스케줄링할까?
* 대표적인 기법 ICOUNT
  * 각 스레드가 지금까지 처리한 명령어 수를 확인
  * 명령어를 인출할 때 지금까지 가장 적게 명령어를 처리한 스레드에 우선순위
  * 거시적으로 스레드가 비슷한 명령어를 파이프라인에서 처리하게끔 균형을 맞출 수 있다.
  * 물론 단점도 있고 수 많은 후속 연구가 있다.

동시 멀티스레딩으로 만들어진 두 논리 프로세서에 많은 캐시가 필요하다면 해가 될 수 있다.
* 하이퍼스레딩을 고려하여 캐시를 만들기는 쉽지 않다.
  * 캐시 장치는 동시 멀티스레딩과 무관
* 최악의 경우 하이퍼스레딩으로 인해 더 느려질 수도 있다.
  * 캐시 충돌이 자주 일어나면 성능이 저하
* 그러나 이득을 보는 상황 또한 있다.
  * 한 논리 프로세서가 이미 캐시에 올려놓고
  * 다른 논리 프로세서가 이것을 공유한다면 이득

운영체제도 동시 멀티스레딩을 인지하여 최적화해야 한다.
* 하이퍼스레딩이 적용되면 운영체제는 두 배 많은 논리 프로세서를 보게된다.
  * 이것을 똑같은 물리 프로세서로 보고 스케줄링하는 것은 옳지 않다.
  * 만약 하이퍼스레딩 여부를 알지 못해 다른 코어가 놀고 있는데 하이퍼스레딩 관계에 있는 두 논리 프로세서에 스레드를 할당하면 오히려 성능이 하락
  * 이 때는 다른 물리 코어에 있는 논리 프로세서에 스레드를 할당해야 한다.
  * 윈도우 7부터 이런 점을 고려