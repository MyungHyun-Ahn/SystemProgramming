# Story 03 프로세서의 기본 부품과 개념들
## 마이크로아키텍처란?
프로세서를 만드는 여러 방법론 중 하나

마이크로아키텍처(Microarchitecture)
* 마이크로프로세서 하나를 만드는 데 필요한 알고리즘 및 회로 수준의 구조를 자세히 정의한 것
* '마이크로'를 뜻하는 u를 따서 uarch 라고도 함
* 인텔 펜티엄 프로의 P6 구조가 대표적
  * 펜티엄4를 제외한 거의 대부분의 인텔 프로세서 마이크로아키텍처의 근간

현대 마이크로아키텍처의 설계는 두 단계로 나뉜다.
1. 마이크로아키텍처 설계
2. 로직 설계

마이크로아키텍처 설계 단계
* 목표한 성능을 가능케하는 여러 알고리즘과 테크닉을 개발
* 고안한 아이디어가 합리적인지 성능 모델을 만들어 평가 (시뮬레이터(simulator) 이용)
* 즉, 코딩을 한 뒤 테스트

시뮬레이터는 자신의 아이디어가 사이클과 전력을 얼마나 아낄 수 있는지 예측
* 물론 실제 칩과의 오차는 존재
* 검증된 시뮬레이터 위에서 향상된 성능을 보이면 다른 사람을 설득하기에 충분
* 정제된 알고리즘은 RTL(Register Transfer Language)라는 언어로 기술
* 고급 언어를 실제 하드웨어 설계 언어로 변환

마이크로아키텍처 디자인이 끝나면
* RTL을 실제 하드웨어 구현에 적합한지 테스트하고 가다듬어
* HDL(Hardware Description Language) 언어로 변환
  * 대표적으로 베릴로그(Verilog) 같은 언어가 있다.

## 산술 논리 장치 : 프로세서 속의 계산기
컴퓨터, computer의 영어 단어 뜻은 계산하는(compute) 장치

실제 프로세서 내에서 계산을 담당하는 장치를 산술 논리 장치(Arithmetic Logical Unit, ALU)라 한다.

ALU가 지원하는 연산
* 정수 사칙 연산 : +, -, *, /
* 비트 논리 연산 : AND(&), OR(|), XOR(^), 1의 보수(~)
* 비트 시프트 연산 : <<, >>

이런 기본 연산은 프로세서가 명령어로 바로 지원

x86 ISA 명령어
* 정수 사칙 연산 : add, sub, imul(integer multiplication), idiv(integer division)
* 비트 논리 연산 : and, or, xor
  * ||, && : Boolean 연산은 분기문의 조합으로 구현


ALU 그림

![ALU](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/5b9c5b01-3597-4f29-8045-e5544cc5e9be)


ALU의 인터페이스는 다음과 같이 표현 가능하다.
~~~C++
void ALU(int function, int oprand_A, int oprand_B, int *result, int *flags);
~~~
* A, B : 피연산자 전달
* F : 연산 형태 전달
* R : 계산 결과 값이 반환
* D : 계산 결과의 상태 값 반환 - 오버플로우 여부, 결과 값이 0과 같은지, 페리티 값 등
  * 대표적으로 x86의 EFLAGS(32bit), RFLAGS(64bit) 레지스터가 이에 해당
  * 캐리(Carry) 상태를 가진 비트도 있다. (올림 수)

## 부동소수점 계산
실수는 IEEE754에 약속된 2진수 부동소수점 형태로 표현
* 최상위 1비트 : 부호
* 나머지 : 지수(exponent)와 가수(mantissa)를 표현

float 타입
* 32비트 단정도(single precision)
* 8비트 : 지수
* 23비트 : 가수

double 타입
* 64비트 배정도(double precision)
* 11비트 : 지수
* 52비트 : 가수

IEEE754 부동소수점 표기법은 무한대와 NaN(Not a Number)라는 특수한 코드도 있다.

부동소수점 데이터를 다룰 때는 연산 순서에 따라 '정밀도'가 바뀔 수 있음을 인지해야 한다.
* 매우 큰 수와 매우 작은 수의 연산 순서가 바뀌는 경우 정밀도 차이가 작지 않다.

이렇게 복잡한 표현 방식을 가진 것을 하드웨어로 만드는 일은 만만치 않았다.
* 회로의 집적도가 낮았던 과거에는 부동소수점 처리기(Floating Point Unit, FPU)를 프로세서와 같은 다이에 놓을 수 없었음
* 프로세서 외부에 추가한 보조 연산 장치로 지원
* 지금은 물론 FPU가 프로세서 내로 들어왔다.

인텔 펜티엄 프로세서의 FDIV(floating division) 버그
* 과거에는 RISC 형태의 컴퓨터가 부동소수점을 더 빠르게 계산
* 펜티엄 설계자들이 더 빠른 장치를 만들고자 SRT 알고리즘 도입
  * SRT 알고리즘 : 테이블을 이용하여 빠르게 계산하는 알고리즘
* 인텔의 엔지니어가 테이블의 5개 항목을 실수로 빠뜨렸는데 발견되지 못하고 발매
* 엄밀한 계산이 필요한 분야에서 치명적인 버그 발생

즉, 위 사례는 부동소수점 처리기 설계가 절대 쉽지 않음을 보여준다.

## 계산하는데 필요한 시간은?
덧셈이나 비트 AND 연산은 단순하다. (빠르게 완료)

정수 곱셈, 나눗셈은 이보다 훨씬 복잡하다.
* 펜티엄4에서 덧셈에 비해 각각 14배, 60배가 더 걸린다.

비트 연산 중 시프트와 회전(rotate)도 덧셈에 비해 4배가 더 걸린다.

보통 프로세서는 처리 시간에 따라 단순 정수 연산, 복잡한 정수 연산, 부동소수점 계산기로 분리 처리
* 연산의 종류에 따라 회로를 분리하여 사용하는 것이 성능 상 이득

특히 정수 곱셈과 나눗셈은 성능을 높이는 여러 기술이 적용되었다.
* 정수 곱셈은 2진수 두 수를 빠르게 곱하는 부스(Booth) 알고리즘으로 구현
* 정수 나눗셈은 수십배 느리지만 프로그램에 자주 등장하지는 않음
  * 조기 탈출(early exit)이라는 테크닉으로 평균 연산 시간을 대폭 줄림
  * 정수 나눗셈은 통상 루프로 구현되는데, 필요한 루프 순환 횟수를 미리 계산하는 방식
  * 최악의 경우는 그대로지만, 평균적으로 많은 시간을 단축

## 또 다른 종류의 계산
벡터 계산
* 과학이나 멀티미디어 프로그램에서 매우 많이 접할 수 있다.
* 이 부분을 처리하는 것은 'Make common case fast'의 원리와 맞다.
* GPU에서 흔히 볼 수 있는 연산 (Story 11)

## 클록, 1 사이클이 가지는 의미
과거에는 CPU 제품명에 CPU 클록 속도가 포함
* 인텔 펜티엄 133 - 동작 속도가 133MHz

디지털 회로에서 1Hz는 정확히 무슨 뜻일까?

클록은 오케스트라의 지휘자와 비유 가능하다.
* 음악을 마디나 동기로 구분한다.
* 한 마디를 연주하고 다음 마디로 넘어가려면 지휘자의 손을 봐야 한다.
* 지휘자의 박자에 여러 연주자들이 맞춰야 아름다운 화음이 만들어진다.

컴퓨터 프로세서도 정확히 일치한다.
* 프로세서가 처리하는 명령 하나 : 마디
* 이런 마디를 디지털 회로에서는 상태(State)라고 함
* 그래서 디지털 회로를 유한 상태 기계(Finite State Machine)이라 함

기계어 명령 하나를 처리하려면 시작 상태에서 중간 상태를 거쳐 마지막 상태가 되어야 처리가 완료된다.
* 명령어 하나 : 연주할 내용
* 클록 : 지휘자
* 디지털 회로는 다음 상태로 넘어가려면 반드시 클록 신호가 있어야 한다.

즉, 2GHz의 프로세서는 1초에 20억번의 클록 신호를 발생시킨다.
* 프로세서의 내부 상태가 1초에 20억번 변할 수 있다.
* 1초에 20억개의 연산이 완료될 수 있다.

## 메모리 계층
컴퓨터의 연산 결과는 궁극적으로 메모리의 상태 변화로 볼 수 있다.

우리가 쓰는 컴퓨터는 보통 프로그램 내장형 방식인 폰 노이만 구조
* 프로그램과 데이터가 구분없이 메모리에 저장, 프로세서가 불러와 실행

메모리는 컴퓨터에서 매우 중요한 역할을 한다.
* 실제로 메모리 대역폭(bandwidth)과 레이턴시(latency)를 개선하는 것이 컴퓨터 성능 향상에 큰 영향

대역폭 : 단위 시간에 얼마나 많은 데이터가 흐를 수 있는가\
레이턴시 : 원하는 작업을 완료하는데 걸리는 시간

메인 메모리는 현재 DRAM(Dynamic Random Access Memory)로 구현된다.
* 문제는 현재 기술로는 프로세서와 멀리 떨어져 있다.
* 데이터를 가져오는데 100 사이클이 훌쩍 넘는다.
* 프로세서와 속도 차이도 점점 커져간다.

속도 차이를 극복하기 위해 캐시 메모리가 필요하고, 중요성은 말할 필요도 없다.

메모리 계층(Memory Hierarchy)

![메모리계층](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/af49cbff-2ac1-4417-8950-049dafa7cfd7)


레지스터(register)
* 가장 빠르면서 값이 비싼 메모리
* 컴퓨터 구조적 상태의 일부분

프로세서가 메모리에서 데이터를 읽고 계산하려면 임시 저장 장소가 필요
* 레지스터가 바로 이 역할을 한다.

범용 레지스터(general purpose register, GPR)
* 계산 등 다양한 목적으로 사용되는 레지스터

프로그램 카운터(program counter, PC)
* 현재 수행중인 명령어의 주소를 가지고 있다.
* 중단점을 걸고 멈췄을 때의 위치가 바로 PC의 위치
* x86에서는 IP(Instruction Pointer)라는 이름으로 불린다. (32 : EIP, 64 : RIP)

컨트롤 레지스터(control register, CR)
* 시스템 내부 상태를 관리
* 시스템의 여러 상태를 기억한다.
* CR0, CR4 : 컨트롤 상태
* CR3 : 프로세스의 페이지 테이블(가상 메로리 변환을 위한 자료구조)

지금까지 다룬 레지스터는 외부로 노출되는, 즉, 프로그래머가 볼 수 있는 레지스터
* 구조적 레지스터(architectural registers) 혹은 논리 레지스터(logical registers)라 한다.
* 프로그래밍 관점에서 외부로 노출되는 인터페이스
* 구조적 레지스터의 수는 많지 않다.

실제 레지스터의 수는 훨씬 많다.
* 프로세서 내부에서 사용되는 레지스터를 물리 레지스터(physical register)라 한다.

구조적 레지스터와 물리 레지스터 사이를 관리하는 알고리즘과 테이블이 필요하다. (Story 08)

프로세서는 이 레지스터를 레지스터 파일(register file)이라는 장치로 구현
* 레지스터의 배열에 읽기/쓰기 함수가 제공되는 형태로 이해하면 편하다.
* 레지스터 파일은 매우 빠르게 접근 가능해야 한다. - 대부분은 한 사이클에 데이터를 가져올 수 있다.
* 프로세서 내에서 가장 빠른 메모리 장치
* 따라서 자연스레 컴파일러는 최대한 레지스터를 효율적으로 쓰도록 최적화
* 레지스터에 여유가 있다면 불필요한 변수를 실제 메모리에 할당하지 않고 레지스터로 대체하는 최적화 진행

캐시가 필요한 이유(Story 12와 15에서 자세히 알아봄)
* 메인 메모리와 프로세서 레지스터 사이의 속도 차이를 극복하기 위함
* 자주 쓰는 데이터를 캐시에 넣고 메모리까지 가는 시간을 절약
* 이것을 어떤 정책으로 관리할지도 매우 중요

메인 메모리는 현재 작은 면적에 많은 데이터를 저장할 수 있는 DRAM 구조 활용
* 멀티코어에서는 많은 코어가 동시에 데이터를 요구하므로 대역폭이 더욱더 중요해짐
* GPU에서 작은 코어가 대량의 데이터를 필요로하므로 메모리 대역폭은 대표적인 성능 병목 지점

## 컨트롤 장치
프로세서가 하는 일은 프로그램에 있는 명령어들의 흐름을 하나하나 처리하는 것
* 누가 이 명령어를 해독하고 이것을 적절한 ALU에 넣어 결과값을 얻게할까?
* 이런 것들을 통칭하여 컨트롤 장치(control unit)이라 한다.
* 대조적으로 ALU나 레지스터 파일은 데이터패스(datapath)로 구분

데이터패스는 ALU와 레지스터 파일의 인터페이스에서 보듯 하나의 컴포넌트로 추상화 가능

컨트롤 장치는 이들을 조율하여 명령어를 처리하는 프로세서의 뇌 역할을 한다.
* 마이크로아키텍처의 큰 영향을 받는다.
* 파이프라인과 비순차 실행은 이에 해당

## 프로세스와 스레드
일반적으로 운영체제 교과서에서 프로세스
* '실행중인 프로그램'이라 정의
* 프로그램을 실행, 운영체제는 프로세스를 만들고 프로세서 위에서 실행
* 대다수 교과서에서는 프로세스가 프로세서를 사용하는 단위라 함
* 멀티태스킹을 위해 시분할 방식으로 문맥교환(context switching)을 하며 프로세스가 동시에 하나의 물리적인 프로세서 위에서 작동하는 것처럼 보인다.
* 여기서 문맥교환 비용을 줄이려고 등장한 가벼운 프로세스 개념, 스레드(Thread)

그러나 이것은 오래된 내용이다.
* 요즘은 프로세스가 CPU를 사용하는 단위가 스레드
* 프로그램을 실행하면, 운영체제는 프로세스 자료구조를 만들지만 실제로 실행되려면 반드시 스레드 자료구조를 만들어야 함
* 프로그램의 진입점(main 함수)을 얻어와 만들어진 메인 스레드에서 실행된다.
* 스레드는 한 프로세스 내에서 여러개가 만들어질 수 있다.

컴퓨터 구조적 상태는 현재 실행 중인 프로세스와 스레드의 상태를 보여준다.

스레드가 가지고 있는 것
* 레지스터 상태
* 호출스택의 상태
* 하나의 실행 흐름 유지

프로세스가 가지고 있는 것
* 프로세스 ID(PID)
* 주소 공간
* 프로세스 우선순위
* 현재 열려 있는 파일들의 목록

위 정보들이 바로 문맥(context)
* 운영체제는 문맥 교환으로 여러 스레드와 프로세스를 제한된 프로세서에 최대한 공정하게 배분

현재 운영체제는 선점형(preemptive) 멀티태스킹 구현
* 정해진 시간이 지나면 스레드가 계속 프로세서를 요구해도 무시하고 다음 스레드에 기회를 준다.
* 이것이 라운드-로빈 스케줄링(round-robin scheduling) 방식

## 가상 메모리
운영체제에서 가장 중요한 개념

가상 메모리(Virtual Memory)란?
* 프로세스마다 연속적이고 충분히 큰 가상 메모리가 있게 하여 물리 메모리보다 더 큰 메모리를 가능하게 하며, 운영체제의 안정성을 크게 높인다.

프로세서의 구현은 가상 메모리와 매우 밀접\
가상 메모리를 물리 메모리로 변환하는 작업은 매우 빈번하며 하드웨어가 처리\
예외 상황이 발생하면 운영체제와 협력하여 처리

실제로 C/C++ 프로그램에서 확인할 수 있는 변수의 주소는 가상 메모리 주소

주소 공간(address space)
* 32비트 운영체제에서 각 프로세스는 232=4GB 만큼 가상 메모리를 가진다.
* 프로세스는 각자 4GB 만큼 메모리가 있다고 생각하고 프로그램을 실행
* 이 공간은 커널 영역, 텍스트(코드) 영역, 데이터 영역, 힙, 스택으로 나뉜다.

엄밀히 말하면 KB, MB, GB 같은 단위는 10진수 단위
* 1KB = 1000byte
* 2진수 기반은 KiB(키비 바이트)

64비트 컴퓨터에서는 16엑사바이트=16,777,216기가바이트의 주소 공간을 가질 수 있다.
* 그러나 실제 구현 상의 제약으로 모두 사용하지는 못한다.
* AMD의 경우 48비트(=256테라바이트)의 가상메모리, 52비트의 물리 메모리만 지원

가상 메모리의 개념은 축복같은 일
* 실제 컴퓨터의 메모리가 작더라도, 32비트 운영체제면 4GB 메모리가 있다고 생각하고 개발해도 되도록 함

운영체제의 안정성을 크게 높인다.
* 다른 프로세스가 데이터를 엿보거나 조작하는 것을 방지
* 가상 메모리의 존재로 다른 프로세스의 데이터 주소를 얻어와도 무용지물
* 이런 제약은 다른 프로세스의 데이터를 얻어올 때 장애가 됨(IPC, 파이프, 공유 메모리 등으로 해결)

가상 메모리를 물리 메모리로 변환하는 방법
* 가상 주소를 물리 주소로 변환하는 함수를 만들고, 그 내용을 기억
* 가상 주소의 범위가 232 혹은 264이므로 바이트 단위로 기억하는 것은 불가능

주소 변환을 용이하게 하기 위해 '페이지(page)'라는 고정 크기 단위로 나누어 가상 메모리를 관리
* 한 페이지의 크기는 보통 4KB
* 운영체제는 각 프로세스마다 페이지를 테이블(page table)을 이용해 물리 메모리로 변환
* 하드웨어에서 이 부분을 가속하기 위해 메모리 변환 장치와 TLB(Translation Lookasize Buffer)라는 캐시를 지원

가상 메모리는 항상 페이지 단위로만 할당하고 반환
* 운영체제에서 가상 메모리 할당 단위는 항상 페이지 크기의 정수배
* malloc 혹은 new가 페이지 크기보다 작은 메모리를 할당하는 방법
  * 운영체제로부터 미리 페이지 단위의 커다란 가상 메모리(프로세스 힙)를 얻어온 뒤(VirtualAlloc) 작은 크기로 나누어 프로그램에게 나눠준다.

각 페이지는 물리주소의 어딘가에 매핑되어 있다.
* 프로그램이 연속적으로 생각했던 가상 메모리가 실제로는 물리 메모리에서 떨어져 있을 수 있다.
* 두 프로세스에서 다른 가상 주소지만 같은 물리 주소에 매핑될 수 있다.(DLL)
* 페이지가 디스크(하드디스크)에 존재할 수 있다.

프로세스가 최초로 실행되면 코드와 데이터는 디스크에 있다.\
또한 사용하지 않는 페이지를 디스크로 보내기도 한다.
* 운영체제를 설치할 때 사용하는 페이지/스왑 파일이 이 때문에 필요

변환하고자 하는 가상 주소가 아직 매핑되지 않은 상태
* 페이지 테이블에 없는 예외상황
* 페이지 폴트(page fault)

페이지 폴트가 발생하면?
1. 프로세서는 프로그램의 실행을 멈추고 제어권을 운영체제에게 줌
2. 운영체제는 디스크에서 이 페이지 내용을 읽어 메인 메모리 어딘가에 저장하고 페이지 테이블에 매핑 정보를 씀
3. 다시 중단된 부분부터 실행

각 페이지는 권한 여부도 가지고 있다.
* 읽기 권한, 쓰기 권한, 실행 권한의 유무가 페이지에 설정
* 페이지 권한을 검색하여 프로그램의 안정성을 높인다.
* 완벽한 대책은 아니지만 최소한의 페이지 접근 권한을 두어 프로그램이 안전하게 실행되도록 한다.