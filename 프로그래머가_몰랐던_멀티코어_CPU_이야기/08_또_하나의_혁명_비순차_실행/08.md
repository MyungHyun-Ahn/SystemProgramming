# Story 08 또 하나의 혁명 : 비순차 실행
지금까지 공부한 파이프라인
* 명령어를 주어진 순서대로만 처리
* 단점 : 사이클의 낭비

비순차 실행 프로세서
* 의존성을 분석하여 먼저 실행할 수 있는 명령을 미리 실행
* 명령어 완료 시간을 크게 향상
* 명령어 수준 병렬성이라는 것을 찾아 활용

이를 더 잘 작동할 수 있도록하는 슈퍼스칼라 처리

## 비순차 슈퍼스칼라 프로세서가 필요한 이유
순차(in-order) 프로세서
* 명령어를 순서대로 처리하는 프로세서
* 단점 : 앞의 명령어가 오래걸리면 대기

프로그램에서의 예
~~~C++
1:  x = data[10];
2:  y = x + 10;
3:  a = b / c;
4:  d = e * f;
~~~
* 만약 1번 명령이 캐시 미스가 나서 메인메모리에서 값을 가져온다면?
  * 이는 100사이클이 넘게 걸리는 작업
* 당연히 2번 명령은 대기, 3, 4번은 그럴 필요가 없다. 먼저 실행시키면 좋다.
* 그런데 순차 파이프라인 구조에서는 그럴 수 없다.

비순차 실행(Out-of-Order Execution, OOOE)에서는 가능하다.
* 이것을 구현하려면 3번 명령이 1, 2번 명령과 무관함을 알아야 한다.
* 1번 명령이 멈춰있는 상황에 3번 명령을 스케줄링할 수 있어야 한다.

여기서 명령어 처리율을 더 높이는 방법
* 1번 명령이 캐시미스를 겪는 동안 3, 4번 두 명령어를 동시에 처리할 수 있다면?
* 지금까지는 파이프라인이 오직 1개, 즉 IPC(Insturction Per Cycle)가 1

슈퍼스칼라(superscaler) 프로세서
* 파이프라인의 복제 -> 3, 4번 명령을 병렬로 처리
* 파이프라인이 여러개 있어 여러 명령어를 동시에 처리하는 구조
* 비순차 실행으로 명령어 처리 성능을 크게 높일 수 있다.

위 소스에서 걸리는 사이클 비교
* 캐시미스 메모리 로드 : 100사이클, 덧셈 : 1, 곱셈 : 4, 나눗셈 : 10이라 가정
* 순차 프로세서 : 100 + 1 + 4 = 115사이클
* 비순차 프로세서 : 101사이클 : 캐시미스 동안 3, 4번 명령 수행
* 여기서는 이미 캐시미스가 100사이클이라 차이가 크지 않다. : 실제라면 몇배 이상 단축 가능

## 비순차 실행의 원리 : 명령어 수준 병렬성
비순차 실행은 명령어 수준 병렬성(Instruction Level Parallelism, ILP) 기반으로 동작
* 프로그램의 순서가 아닌 데이터 흐름에 따라 명령어를 처리

### 스레드 수준 병렬성(Thread-Level Parallelism, TLP)
* 멀티 코어에서 실제로 여러 스레드가 물리적으로 실행
* 싱글 코어에서 운영체제의 시분할 멀티태스킹, 논리적으로 동시에 실행된다고 보임
* 명시적으로 프로그래머가 멀티스레드로 프로그램을 작성했을 때 얻는 병렬성

### 명령어 수준 병렬성(Instruction-Level Parallelism, ILP)
* 프로그래머가 멀티스레드로 작성하진 않은 프로그램에도 동시 실행 가능한 명령어를 찾을 수 있다.
* TLP보다 규모가 작은 병렬성

~~~C++
1:  x = y + 1;
2:  a = b * 2;
~~~ 
* 서로 순서에 상관없이 동시 실행 가능
* 누가 먼저 실행되어도 컴퓨터 구조적 상태는 같다.
* 즉, 프로그램의 의미(semantic)를 정확히 실행시키는 것
  * 어떤 연산은 flag 레지스터를 변경 : 이에 대한 의존성도 물론 고려해야 한다.

프로그래밍 언어 규칙에 반드시 코드에 적힌 순서대로 수행하라는 조건은 없다.
* 데이터 의존성만 지켜주면 된다.

이것이 바로 ILP

아래 소스의 명령어 4개를 의존성에 따라 그린 그래프

![8-01](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/4e9ac05e-e4cb-43a4-8a3e-06c7032ba971)

* 프로세서가 모든 명령을 1사이클에 처리한다 가정
* 순차 프로세서 : 4사이클
* ILP를 찾아 병렬 수행 : 2사이클

ILP를 계산
* 의존성 그래프를 그린 뒤, 꼭대기부터 바닥까지의 길이(임계 경로, critical path)를 구한다.
* ILP = 전체 명령의 개수 / 임계 경로
* ILP는 이론적인 프로그램의 속성, 성격에 따라 크게 다르다.
* 싱글 스레드 프로그램에서 추출할 수 있는 병렬성의 이론적인 상한값

ILP와 IPC를 착각하면 안된다.
* ILP : 프로그램의 고유한 속성
* IPC : 프로세서 구현 방식에 따라 결정
* 매우 이상적인 컴퓨터, ILP = IPC
  * 실제로는 하드웨어 제약으로 훨씬 작은 IPC 값을 얻는다.
* ILP는 컴파일러가 대신 찾아줄 수 있다.

스케줄링 관점에서 비순차 실행
* 동적으로 명령어 사이의 의존성을 파악해 스케줄링 : 동적 스케줄링(dynamic scheduling) 기법

## 슈퍼스칼라 파이프라인 구조
슈퍼스칼라(superscalar)
* 단순히 파이프라인이 여러 개 있어 동시에 명령어를 처리할 수 있는 구조

![8-02](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/0a774980-e9ee-4a53-84cc-25b33afcd6e0)

파이프라인이 2개가 되면?
* 이상적으로 최대 두 개의 명령어가 투입과 완료
* 즉, IPC = 2
* 동시에 투입/완료 가능한 명령어 개수 N : N-이슈, N-와이드, N-웨이 슈퍼스칼라로 표현
* 이상적으로는 N개의 명령을 처리 가능
* 실제로는 여러 제약 때문에 N개 보다 적은 명령어를 넣을 수 있을 때가 일반적

현대 x86 프로세서는 보통 2~4-와이드 구조
* 8~16-와이드 구조 또한 고려되는데 실제로는 이보다 작게 구현
* 일번적인 하드웨어에서 찾을 수 있는 IPC가 보통 5를 넘지 않기 때문

슈퍼스칼라 프로세서의 구현은 수많은 어려움을 만든다.
* N-와이드 프로세서, 최대 N개의 명령어를 읽어와야 함
* 명령어 캐시가 이를 쉽게 해결하지 못한다.
* 명령어가 제대로 정렬되지 않았거나, 다른 캐시 라인에 걸쳐있으면 쉽지 않다.
* 읽은 명령어 사이에 분기문이 끼어있다면 문제가 어려워진다.
* 바이패스 로직 역시 복잡해진다.

비슈퍼스칼라 프로세서는 한 명령어에만 계산 결과 전달
* 슈퍼스칼라는 이것이 N배로 커진다.

## 비순차 실행의 구현 : 토마슐로 알고리즘
어떤 명령이 실행 가능하다.
* 이 명령이 취하는 피연산자가 모두 연산을 마쳤을 때
* 따라서 어떤 명령의 피연산자가 완료되는 것을 탐지한다면 비순차 실행이 가능

![8-03](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/42ac6b1a-6bba-47fb-a141-164fbb262666)

비순차 프로세서 파이프라인의 주요 4단계
1. 명령어 인출/해독 : 명령어를 모두 읽어 큐에 넣는다.
2. 스케줄링 단계 : 반복적으로 명령어의 피연산자가 준비되었는지 검사한다.
3. 실행 : 피연산자가 준비되었다면 실제 계산을 수행한다.
4. 결과 쓰기 : 완료되면 자신의 결과를 필요로하는 명령어에 완료되었음을 알려준다.

이 뼈대 알고리즘에 살을 붙여보자.
1. 명령 1은 큐를 할당받고 자리잡는다. 
  * 레지스터 x에 값을 쓸 것이므로 뒤 명령 중 x를 사용하는 명령은 자신을 반드시 기다리도록 체크
  * 명령 1은 메모리 로드이므로 캐시미스가 나서 긴 시간이 걸린다 가정
2. 다음 명령 2를 큐에 넣는다. 
   * 레지스터 x를 체크해보니 명령 1을 기다리라 설정됨, 명령 1을 기다린다.
3. 명령 3이 큐에 들어온다. 
   * 레지스터 b와 c는 그냥 읽을 수 있다. 
   * ALU를 할당하고 실행한다. 
   * 큐에서 빼고 완료되었음을 알린다.
4. 명령 4는 명령 3과 동일
5. 명령 1의 데이터가 도착했다.
   * 명령 1은 레지스터 파일의 값을 갱신한다.
   * 큐에 기다리고 있는 명령에 알린다.
   * 명령 2는 이것을 확인하고 레지스터 x의 값을 읽을 수 있다.

위 과정에서 데이터 의존성에 따라 명령어가 스케줄되는 것을 알 수 있다.
* 레지스터 x에 의존적인 명령 2는 명령 1이 완료될 때까지 기다릴 수 있었다.
* 이것이 바로 비순차 실행의 기원인 토마슐로(Tomasulo) 알고리즘

## 명령어 윈도우
명령어 윈도우(Instruction Window)란?
* 앞에서 이야기한 ILP는 이상적인 상황을 가정, 크기가 아주 작은 코드
* 실제 프로그램 크기는 매우 크다. - 코드 전체를 분석하여 ILP를 얻는 것은 쉽지 않다.
* 따라서 비순차 프로세서에서 찾는 ILP는 매우 제한적인 범위 내에서 찾는다.
* 이 범위가 바로 명령어 윈도우이다.

128개의 명령어 윈도우를 가진다는 의미
* 128개의 명령어 속에서 ILP를 찾을 수 있다.
* 128개의 명령어를 잠시 들고 있으며 비순차 실행을 수행한다.

명령어 윈도우는 보통 연속적으로 움직인다.
* 명령어 윈도우 안에서 가장 오래된 명령어가 완료되면 한칸씩 이동
* 인-플라이트(in-flight) 명령어 : 명령어 윈도우 안에 있는 명령어

![8-04](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/21239d88-89eb-4426-a56c-302597fac04a)

최신 프로세서에서 명령어 윈도우의 크기는 보통 100여 개
* 클수록 당연히 좋지만 하드웨어 구현의 제약이 있다.

컴파일러가 ILP를 찾는 방법(Story 17)
* 컴파일러는 하드웨어 제약이 없으므로 더 큰 범위에서 ILP를 찾을 수 있다.
* 보통 수천개

## 레지스터 리네이임으로 가짜 의존성 제거
비순차 프로세서에서는 반드시 가짜 의존성을 주의 깊게 다뤄야 함
* 순차/비순차 모두 데이터/메모리/컨트롤 의존성은 신중히 고려해야 함
* 일단 여기서는 데이터 의존성만 고려

기계어 상 데이터 의존성은 레지스터 이름이 겹치는 것으로 찾아낼 수 있다.
* 피연산자와 목적지에 있는 레지스터 이름만 비교하면 찾을 수 있다.
* WAW/WAR은 변수 이름 교환으로 쉽게 제거될 수 있는 가짜 의존성이다.

순차 프로세서에서는 가짜 의존성으로 해저드는 일어나지 않는다.

![8-05](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/a9282682-c37c-4a66-b321-0d895993c54b)

그런데 비순차 실행에서 가짜 의존성은 문제를 일으킨다.
* 명령 1과 명령 2를 뒤바꾸어 실행하면 문제
* 이름 바꾸기로 가짜 의존성을 없애면 비순차 실행 기회를 얻을 수 있다.

레지스터 리네이밍(Register Renaming)
* 비순차 프로세서에서 높은 ILP를 얻고자 레지스터 이름을 바꿔 가짜 의존성을 제거하는 작업

~~~C++
1:  r2 = r1 + 5 => F0 = r1 + 5 // r2를 F0로 변경
2:  r0 = r2 + 4 => F1 = F0 + 4 // r2를 F0, r0를 F1으로 변경
3:  r1 = r0 + 1 => F2 = F1 + 1 // r0를 F1, r1을 F2로 변경
4:  r1 = r0 + 2 => F3 = F1 + 2 // r0를 F1, r1을 F3로 변경
5:  r3 = r1 + 3 => F4 = F3 + 3 // r1을 F3, r3를 F4로 변경
~~~

세부적인 구현 방법과 정책
* 항상할 필요는 없다.
* 그런데 복잡하므로 명령어를 해독할 때 모든 목적지 레지스터의 이름을 바꾼다.
* 뒤따르는 명령어는 바뀐 이름을 따른다.

명령어 상의 레지스터 이름은 ISA가 정의하는 것
* ISA의 레지스터 수는 적다.
  * 추가 레지스터가 있어야 레지스터 리네이밍이 효과적
* 따라서 ISA의 구조(논리) 레지스터 파일(ARF)과 물리 레지스터 파일(PRF)로 나눈다.
* 논리 레지스터 파일은 하위 호환성 때문에 변경이 어렵다.
* 물리 레지스터 파일은 자유롭게 설계할 수 있다.(레지스터 수 등등)
  
레지스터 변경 파일(Register Alias Table, RAT)
* 논리 레지스터파일과 물리 레지스터 파일을 매핑시켜 관리한다.
* 매핑(변경) 내역을 기억하는 자료구조이다.

논리 레지스터는 r0~3, 물리 레지스터는 F0~9까지 있는 상황에서 변경 규칙
* 명령어의 목적지 레지스터의 이름을 현재 가능한 물리 레지스터로 바꾸고 RAT에 기록
* 다음 명령어가 레지스터를 읽을 때 RAT를 살펴보고 매핑 정보를 본 뒤 물리 레지스터를 읽음
* 만약 물리 레지스터에 여유가 없다면 스톨
* 명령어가 완료되면 RAT 값을 초기값, 논리 레지스터로 바꿈
  * 자신이 논리 레지스터에 쓰는 마지막 값인지 보고 결정해야 한다.

## 동적 명령어 스케줄링 : Reservation Station
비순차 실행의 핵심은 동적 명령어 스케줄링
* 피연산자가 완료되는 순서대로 처리하려면 스케줄링 장치가 필요

Reservation Station(RS) 장치
* 어떤 큐가 있어 명령어가 머물면서 자신의 피연산자가 완료되었는지 감시하는 장치
* 비순차 실행에서는 명령어를 해독한 후 RS 장치로부터 하나의 슬롯을 할당받도록 한다.

명령어가 RS에 자리잡으면 하는 두 가지 작업
* Wake-up(끼우기) 작업 : 어떤 명령어의 모든 피연산자가 완료되었는지 감시하는 작업
* Select(선택) 작업 : 필요한 계산 장치를 스케줄링하여 할당하는 작업

인텔 네탈렘 구조의 RS

![8-06](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/a56db8d6-6c23-42d2-a874-b92c6f95afd3)

* RS는 총 36개
* 'Unified'는 명령어 종류에 상관없이 RS를 통합했다는 것
* 어떤 프로세서는 명령어 종류에 따라 구분했을 수도 있다.

'Port'라는 것이 RS와 실행 장치를 연결하고 있다.
* 위 구조에서 RS는 36개의 명령어를 담을 수 있고, 15개의 실행 장치가 있다.
* 최악의 경우 36 : 15 의 스케줄링 회로를 구현해야 한다.
* 즉, 6개의 포트로 묶는다.
* 36 : 6 의 스케줄링만 구현하면 된다.

RS는 크기를 늘리기 매우 어렵다.
* 캐시처럼 마구 증가시키는 장치가 아니다.
* Wake-up 작업이 매우 복잡하기 때문
* 사이클마다 RS에 있는 명령어는 매 사이클마다 자신의 피연산자가 완료되었는지 들어야하기 때문

4-와이드 슈퍼스칼라의 경우
* 최대 4개의 명령어가 완료
* 36개의 명령어가 RS에 있고, 최대 3개의 인자를 가지므로
* 108개나 되는 피연산자가 기다릴 수 있다.
* 즉, 매번 108개의 피연산자가 4개의 연산 결과가 일치하는지 비교해야 한다.

위 작업은 CAM(Content-Addressable Memory)라는 하드웨어 장치로 구현된다.
* 매우 빠르게 어떤 데이터를 찾는데 쓰이는 장치
* 이 장치는 매우 복잡해서 쉽게 늘릴 수 없다.

따라서 RS와 wake-up 및 select 로직은 확장하기 매우 어렵다.
* 이 부분이 현대 비순차 마이크로프로세서 파이프라인 구현의 병목지점

## 순서대로 완료되게 하는 리오더 버퍼
비순차 프로세서라도 모든 것이 뒤죽박죽은 아니다.
* 명령어 인출과 해독은 여전히 순차
* 비순차는 오직 실행 단계에서 피연산자가 먼저 완료되는 순서로 진행

간과한 사실 : 명령어 완료의 순차성
* 인출/해독 : 순차, 완료 : 비순차
* 프로그래머에게 혼란

### 리오더 버퍼(Re-Order Buffer, ROB)
* 명령어가 완료되는 것을 순차적으로 하게하는 것
* 명령어가 해독되면 RS 뿐만 아니라 ROB도 할당 받는다.
* 한 명령어는 실행이 완전히 완료될 때까지 늘 ROB에 머물러야 한다.
* 따라서 사실상 ROB의 크기가 명령어 윈도우를 결정한다.

RS는 실행할 수 있는 시점에 떠날 수 있다.
* 보통 RS는 30여 개, ROB는 100여 개로 훨씬 많다.

![8-07](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/3911b858-91ed-4227-a8bd-1dd20f02db16)

ROB는 일종의 환형 큐이다.
* 명령어가 해독되면 ROB에 자리잡는다.
* 실행을 마치면 완료되었다고 기록한다.
* 완료되자마자 밖으로 나갈 수 있는게 아닌 자신이 ROB에서 가장 오래된 명령어일 때 정말로 완료할 수 있다.

이 과정을 커밋(Commit), 퇴장(retirement), 마침(graduation)으로 표현한다.

ROB로 순차적으로 명령어를 커밋하는 이유
* 폴트(fault)와 예외처리

~~~C++
1:  r3 = r1 + r4;
2:  r4 = r7 / r1;     <= 0으로 나눔 예외
3:  r6 = Load [r7];   <= 페이지 폴트
~~~
* 의존성이 없어 동시에 실행될 수 있다.
* 그런데 명령 3이 명령 2가 되기 전에 수행 시작, 페이지 폴트를 만남
* 페이지 폴트는 운영체제가 개입해 처리해야 한다.
* 명령 2가 완료되지 않았는데 페이지 폴트를 띄우고 운영체제로 제어가 넘어갔다.
* 프로그래머는 혼란을 겪는다.

따라서 비순차 프로세서에서는 예외나 폴트 역시 하나의 결과로 간주해 발생하는 시점에 어떤 일을 하는게 아니다.
* ROB에서 기다리고 있다 자신의 커밋 차례에 외부로 알린다.

## 비순차 프로세서 파이프라인

순차 방식의 프로세서와 비순차 실행의 파이프라인은 아무런 관련이 없다.

비순차 프로세서의 주요 파이프라인 단계

![8-08](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/b4e12d4a-4186-47da-b1e0-6b9b9312bb5f)

비순차 프로세서의 처리 과정을 크게 분류하면
1. 명령어 인출/해독
2. 자원 할당(ROB와 RS)
3. 비순차 실행
4. 커밋

비순차 프로세서의 주요 파이프라인 단계 - 위 단계를 좀 더 세분화

![8-08](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/b4e12d4a-4186-47da-b1e0-6b9b9312bb5f)

이 과정을 요약해보자.
1. 명령어 인출
    * 순차 프로세서와 큰 차이는 없으나 슈퍼스칼라 구조이므로 더욱 복잡
2. 명령어 해독
    * x86 프로세서라면 RISC 형식의 마이크로 명령어 변환
3. 레지스터 리네이밍
    * 가짜 의존성 제거를 위한 레지스터 이름 바꾸는 작업
4. 이슈 혹은 할당(allocation)
    * RS, ROB에 할당
5. 스케줄링
    * 피연산자 완료를 매 사이클 체크
    * 준비가 완료되면 실행 장치를 스케줄링
6. 실행
    * 진짜 계산
7. 쓰기
   * 연산의 결과를 ROB나 물리 레지스터 같은 곳에 씀
   * 아직 커밋되지 않았기에 결과는 노출되면 안됨
8. 커밋
    * 차지했던 자원을 반환
    * 자신의 결과를 반영
    * 구조 레지스터 파일이나 메모리 갱신

이것으로 주요 비순차 슈퍼스칼라 파이프라인의 개념을 알아보았다.
* 분기 예측(branch prediction), 투기적 실행(speculative execution)은 이후에 다룬다.
  * 컨트롤/메모리 의존성을 해결