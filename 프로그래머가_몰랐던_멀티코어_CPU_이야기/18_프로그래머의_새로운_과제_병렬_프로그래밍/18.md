# Story 18 프로그래머의 새로운 과제 : 병렬 프로그래밍

## 병렬 프로그래밍은 선택이 아니라 필수
자바, C# 등의 고수준 언어는 하드웨어의 복잡함을 감춰 쉬운 프로그래밍 환경 제공
* 개발자들은 하드웨어의 발전과 변화에 관심을 덜 둠
* 그러나 하드웨어는 속도보다 병렬성을 증대하는 방향으로 발전하고 있다.
* 아무리 프로그래밍 언어와 환경이 쉬워도 병렬 프로그래밍은 어렵다.
* 프로그램에 숨어있는 병렬성을 찾고 버그 없이 효율적으로 활용하는 것은 여전히 어려움

병렬 프로그래밍은 새로운 분야가 아니다.
* 수십 년 전부터 이미 주요 연구 대상
  * 슈퍼 컴퓨터는 처음부터 병렬 구조였다.
* 하드웨어의 발전은 병렬성의 증대라는 방향으로 이루어진다.

병렬 프로그래밍은 매우 어렵다.
* 사람은 순차적으로 생각함
* 병렬로 생각하는 것이 일반적인 인간의 사고 영역이 아니다.
* 여러 명령과 데이터가 동시에 실행되고 갱신되므로 예상치 못한 문제가 자주 발생
* 제대로 동작하는 병렬 프로그래밍을 해도 최적의 성능은 다른 이야기

병렬성과 병행성의 구분
* 병렬성(parllelism)
  * 하드웨어의 성질
  * 병행성이 있는 알고리즘이 실제 병렬 프로세서에서 동시에 실행될 때 병렬로 실행된다고 함
* 병행성(concurrency)
  * 프로그램의 성질
  * 순서가 중요하지 않은 작업을 할 때 병행성을 가진다라고 함

## 기본 개념 : 원자적 실행과 동기화 연산

간단한 덧셈 코드
~~~C++
// i = i + 1; ++i; i++;
1: mov  eax, dword ptr [i]
2: add  eax, 1
3: mov  dword ptr [i], eax
~~~
* 이 작업은 원자적(atomically)로 실행되지 않는다.
  * 원자 연산 : 더 이상 나뉘어지지 않는 연산
* ++i의 세부 단계
  1. 메모리에 있는 i의 값을 레지스터로
  2. 레지스터를 대상으로 덧셈
  3. 다시 메모리에 씀
* 서로 다른 스레드가 이것을 동시에 수행할 때 문제가 생긴다.
* 데이터 레이스(data race) 현상
  * 두 개 이상의 스레드가 공유 자원을 놓고 서로 경쟁적으로 값을 읽고 써서 발생하는 문제
  * 읽기만 한다면 데이터 레이스 문제는 없다.

안전한 경우(a)와 그렇지 않은 경우(b, c)

![18-01](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/0a7f1b7f-0a6c-40a5-ac8a-3edd45fc4404)
* b와 c의 상황에서
  * 누락되는 연산이 발생한다.

그런데 x86 명령어는 정수 덧셈을 하나의 CISC 형식의 명령어로도 제공한다.
~~~C++
1:  inc dword ptr[i]
~~~
* 이러한 명령어라고 해도 파이프라인에서 마이크로 명령어로 분해된다.
* 하나의 기계어처럼 보이지만 멀티스레드 실행에 안전하지 않다.


원자 연산이 되도록 지시 lock 접두어
~~~C++
// Win32
// InterlockedIncrement(&i);
1:  lea     rax, [i]
2:  lock    add dword ptr [i], i
~~~
* 위와 같은 기계어를 직접 C/C++ 코드에 넣을 수는 있지만(x86-64)에서는 불가
* 뮤텍스를 쓰면 되지 않나?
  * 단순한 연산을 원자적으로 하는데 뮤텍스는 낭비
* 컴파일러나 플랫폼이 지원하는 인트린직(intrinsic) 함수를 사용하면 된다.
  * 인트린직 함수 : 1:1로 기계어와 대응
  * Win32에서는 Interlocked* 계열의 함수가 이에 해당한다.
  * 이를 사용하면 lock 접두어가 붙은 연산이 생성
* 모든 연산에 lock 접두어를 붙일 수 있는 것은 아니다.
  * 로드/스토어, 레지스터를 대상으로 하는 연산은 기본적으로 원자 연산을 보장

다른 형태의 원자 연산 compare-and-swap
* 뮤텍스(mutex)와 같은 동기화(synchronization) 객체를 만드는데 쓰인다.

compare_and_wap의 의미
~~~C++
1:  int compare_and_swap(int *val, int test, int new_val)
2:  {
3:      int old;
4:      old = *val;
5:      if (old == test) *val = new_val;
6:      return old;
7:  }
~~~
* x86에서 CMPXCHG라는 연산으로 제공된다.
  * test-and-set, fetch-and-add와 같은 읽고 쓰는 일을 원자적으로 할 수 있다면 동기화 객체를 만드는 기본 재료로 사용할 수 있다.
* Win32에서 InterlockedCompareExchange 명령어로 제공

lock과 unlock의 구현
~~~C++
1:  void mutex_lock(int *lock_var) // lock_var 변수는 0으로 초기화 된다.
2:  {
3:      while(compare_and_swap(lock_var, 0, 1));
4:  }
5:  
6:  void mutex_unlock(int *lock_var)
7:  {
8:      *lock_var = 0;
9:  }
~~~

동기화 연산, 동기화 객체를 정리
1. 뮤텍스(mutex), 세마포어(semaphore)
   * 어떤 코드 영역이나 데이터의 배타적인 접근(상호배제, mutual exclusion)을 보장하는 객체
   * 크리티컬 섹션(critical section) 혹은 락(lock)이라 부름
   * 세마포어는 최대 n명이 공유자원을 동시에 접근할 수 있도록 함
   * 뮤텍스, 크리티컬 섹션은 단 한명만 접근
   * 운영체제에 따라 약간의 의미가 다를 수 있다.
     * 윈도우에서 뮤텍스와 세마포어는 프로세스 사이에서도 작동
     * 크리티컬 섹션은 같은 프로세스 안의 스레드 사이에서만 작동
2. 조건 변수(condition variable)와 이벤트(event)
   * 한 스레드가 어떤 조건이 만족되거나 신호가 올 때까지 잠자도록 함
   * 다른 스레드가 이 조건을 갱신하여 잠자던 스레드를 깨울 수 있음
   * 이벤트는 조건 변수와 비슷하나 세부적인 동작이 다소 다름
3. 배리어(barrier)
   * 참여 중인 스레드가 모두 배리어를 부른 지점에 도달해야만 다음으로 넘어갈 수 있게 한다.
4. 스레드 포크(fork)와 조인(join)
   * 스레드 포크 : 하나의 스레드가 여러 스레드 갈래로 나누어진다는 의미
   * 스레드 조인 : 이 나누어진 스레드가 종료되는 것을 기다리는 것
     * 스레드 조인 함수는 인자로 받은 스레드 리스트가 모두 소멸되거나 적어도 하나가 소멸되어야 반환

## 멘델브로 집합으로 보는 병렬 프로그래밍

간단한 직렬 프로그램을 분석하여 여러 병렬 프로그래밍 방법론을 적용시켜보자.
* 멘델브로 집합(Mandelbrot set)이라는 프랙털(fractal)을 그리는 간단한 프로그램

멘델브로 집합으로 그린 프랙털 이미지

![18-02](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/ed2f4af6-8c2a-494b-8b41-70724a5966c8)
* 멘델브로 집합 : 프랙털 이미지를 만들어주는 복소 평면상의 점 집합을 가리킴
* 프랙털 이미지는 무한히 확대해도 같은 모양이 계속 반복되는 특징을 가진다.
* 이런 이미지를 만들어내는 공식
  * Zn+1 = Zn^2 + C
  * 여기서 Z는 복소수 0으로 시작
  * C 역시 복소수, 시작점
  * Z값이 발산하며 프랙털 이미지를 그린다.

멘델브로 프로그램
~~~C++
1:  int Mandelbrot(complex c, int max_count)
2:  {
3:      int count = 0;
4:      complex z = 0;
5:      for (int k = 0; k < max_count; ++k) // Loop for-k
6:      {
7:          if (abs(z) >= 2.0) break;
8:          z = z * z + c;
9:          ++count;
10:     }
11:     return count;
12: }
13:
14: // 구동함수, int p[max_row][max_col];
15: for (int i = 0; i < max_row; ++i) // Loop for-i
16:     for(int j = 0; j < max_col; ++j) // Loop for-j
17:         p[i][j] = Mandelbrot(complex(scale(i), scale(j)), depth);
~~~
* 간략히 설명하면 두 순환문으로 x, y 평면상의 각 점에 대해 Mandelbrot 함수를 불러 그 결과를 2차원 배열 p에 저장

이미 있는 직렬 프로그램을 병렬화하는 단계
1. 적합한 병렬화 대상 찾기
2. 그 대상의 병렬화 가능한지 코드 분석하기
   * 데이터 의존성 분석하기
   * 충분한 병행성이 있는지 분석하기
3. 코드를 병렬화하기
   * 접근되는 변수가 멀티스레드로부터 안전한가? 동기화가 필요한가?
   * 어떠한 종류의 병렬성을 찾아 어떻게 병렬화할 것인가?
   * 병렬화된 코드를 어떻게 실제 멀티코어에 할당할까?
4. 제대로 돌아가는지 검증하기
5. 최적의 성능을 낼 수 있게 튜닝하기

### 병렬화 대상 찾기
프로그램 성능 최적화를 하고 싶을 때 첫 번째 작업
* 어디가 많은 수행 시간을 차지하는지 찾아내서 문제가 있는지 살펴봐야 한다.
* 병렬화 또한 마찬가지 가장 많은 수행 시간을 차지하는 부분이 자연스럽게 병렬화 대상
  * 프로파일러가 이런 과정을 도울 수 있다.
  * 수행 시간을 많이 차지하는 함수나 명령어를 찾아준다.
  * 이 정보로 병렬화 대상을 찾는다.
* 위 소스는 15라인의 for-i 루프가 가장 많은 수행 시간을 보일 것이다.
* 이 루프를 병렬화 대상으로 하자

## 병렬화 가능한가?
두 번째 작업 - 병렬화 후보가 병렬화에 적합한지 분석하는 일
* 간단하게 병렬화가 되는지, 동기화 객체를 이용해 알고리즘을 수정해야하는지 고민

병렬화가 가능한지 판단하는 방법
* 데이터 의존성을 살펴보는 것
* 지금같은 루프를 병렬화할 때는 루프 전이 의존성을 조사
  * 루프 순환에 대한 의존성 그래프를 그리면 된다.
* 의존성이 없다면 그냥 여러 스레드가 처리하도록 나누기만 하면 된다.
  * embrrassingly parallel : 아무런 노력 없이 그냥 병렬화 되는 루프

## A. pthread/Win32 스레드로 병렬화하기
멘델브로 프로그램의 for-i 루프를 병렬화
* 이상적인 방법 Story 15에서 살펴본 컴파일러의 자동 병렬화 최적화
* 그러나 이 프로그램은 어떠한 컴파일러도 자동으로 병렬화하지 못함
  * 라인 7과 9의 break와 ++count 때문
  * count++의 경우 리덕션(reduction)이라는 형태이므로 병렬화할 수도 있다.
  * 제어 흐름 분석의 까다로움 때문

가장 저수준 방법
* 직접 운영체제나 라이브러리가 지원하는 스레드 함수를 사용
* 리눅스 계열 : pthread
* 윈도우 계열 : Win32 스레드 함수

그전에 선택해야 할 것
* 2차원 평면을 어떤 방법으로 나누어 병렬화할지 결정
* 가장 간단하게는 for-i 루프가 행에 대해 순환하므로 행 단위 분할
* 혹은 열 단위, 격자 모양(행렬 문제에서 가장 캐시 친화적)
* 여기서는 가장 간단한 행 단위로 분할하여 병렬화

~~~C++
1:  struct THREAD_DATA {
2:      int **p;
3:      int my_row_start;
4:      int my_row_end;
5:  }
6:
7:  void *Worker(void *data)
8:  {
9:      THREAD_DATA *td = (THREAD_DATA*)data;
10:     for (int i = td->my_row_start; i <= td->my_row_end; ++i)
11:         for (int j = 0; j < max_col; ++j)
12:             td->p[i][j] = mandel(..., ...);
13:
14:     delete td;
15:     return 0;
16: }
17:
18:
19: for (int i = 0; i < num_threads; i++) {
20:     THREAD_DATA *td = new THREAD_DATA;
21:     td->p = p;
22:     td->my_row_start = (i * max_row) / num_threads;
23:     td->my_row_end = ((i + 1) * max_row) / num_threads - 1;
24:     pthread_create(&threads[i], NULL, Worker, td);
25: }
26:
27: for (int i = 0; i < num_threads; ++i)
28:     pthread_join(threads[i], NULL);
~~~
* 스레드를 생성하는 코드 19~25 라인
* THREAD_DATA 자료구조, new/malloc으로 할당 - 지역 변수로 할당하면 정작 스레드가 이 변수를 사용할 때 파괴될 수 있음
  * 다른 스택에서 생성된 지역 변수를 스레드 사이로 넘기는 것은 위험하다.
* 라인 22-23 작업을 분배하는 계산
* 라인 27-28 스레드 작업이 모두 종료될 때까지 기다리는 코드


지역 변수가 아닌 것들은 병렬화할 때 특별히 고려해야 한다.
~~~C++
int g_data;
int * g_vector = new int[100];

...

for (int i = 0; i < 100; ++i)
{
    static int temp = ...;
    g_data = ...;
    g_vector[..] = ...;
}
~~~
* 이런 루프를 그대로 병렬화하면 문제가 발생한다.
* 예를 들어 temp 변수
  * 병렬화 한다면 데이터 레이스, 루프 전이 WAW 의존성을 만든다.
  * 동적 할당, 전역 변수 또한 마찬가지

사본화(privatization)
* 위 변수가 스레드마다 별도로 있어야 할 때 사본을 만드는 작업

위 소스를 사본화
~~~C++
int g_data[num_threads];
int *g_vector[num_threads];
for (int i = 0; i < num_threads; ++i)
    g_vector[i] = new int[100];

...

for (int i = 0; i < 100; ++i)
{
    static int temp[num_threads];
    temp[tid] = ...;
    g_data[tid] = ...;
    g_vector[tid] = ...;
}
~~~
* 각 변수를 스레드 개수만큼 만들고 고유의 tid를 통해 접근
* 성능상 고려해야할 문제
  * 캐시 라인 특성에 의한 가짜 공유(false sharing) 문제

## B. OpenMP로 병렬화하기
OpenMP
* 대표적인 공유 메모리 구조를 위한 프로그래밍 규약
* C/C++에서 #pragma 컴파일러를 확장하여 간단하게 병렬화할 수 있게 한다.
* OpenMP는 스레드 포크와 조인을 간단한 문법으로 지원
* 작업 분배도 알아서 해준다.

Mandelbrot 프로그램의 OpenMP를 활용한 병렬화
~~~C++
1:  #pragma omp parallel for shared(p)
2:  for (int i = 0; i < max_row; ++i)
3:      for (int j = 0; j < max_col; ++j)
4:          p[i][j] = Mandelbrot(complex(scale(i), scale(j)), depth);
~~~
* Mandelbrot 함수는 재진입 가능한 함수이므로 병렬화 코드에서 특별한 조치가 필요하지 않다.
* 루프 전이 의존성 또한 없어 자유롭게 병렬화 가능하다.
* 그러나 효율을 위해 상위 루프인 for-i에 대해 병렬화 하는데 OpenMP를 이용하면 아주 간단히 할 수 있다.
* parallel for 키워드를 주면 바로 아래에 있는 for-i 루프를 미리 지정된 스레드 개수만큼 작업을 분배한다.
* 그리고 모든 실행이 마치면 자동으로 스레드를 조인시킨다.
  * 코드의 i, j 변수는 for 스코프 내에서만 유효하므로 자동으로 스레드 사본을 생성
  * 결과 값을 쓰는 p는 모든 스레드에 공유, shared로 명시한다.

리덕션 연산 - 매우 익숙한 것
* 간단한 숫자 합의 예

~~~C++
1:  int sum = 0;
2:  for (int i = 0; i < N; ++i)
3:      sum += i;
~~~

위 코드를 어떻게 병렬화?
* sum은 루프 전이 의존성 RAW/WAW/WAR을 모두 만들어 병렬화가 불가능해 보인다.
* 연산의 특성으로 병렬화할 수 있다.
  * 교환 법칙과 결합 법칙
  * 아무 순서대로 더하기만 해도 결과는 같다.
* 이런 연산을 리덕션이라 한다.
  * 계산 결과의 갱신 순서가 중요하지 않을 때
  * 연산자가 교환성과 결합성을 가지면 적용 가능하다.

OpenMP로 병렬화하면
~~~C++
1:  int sum = 0;
2:  #pragma omp parallel for reduction(+:sum)
3:  for (int i = 0; i < N; ++i)
4:      sum += i;
~~~
* 덧셈 형태의 reduction 항목을 추가
* 그럼 이제 OpenMP가 자동으로 이 루프를 여러 스레드로 나누어 각각의 부분합을 구한다.
* 마지막에 부분합을 취합하는 코드를 생성해준다.
* C/C++의 OpenMP에서 지원하는 리덕션 연산
  * +, *, -, &, |, ^, &&, ||

## C. TBB로 효율적으로 스케줄링하기
Mandelbrot은 구조가 간단하여 병렬화가 쉽고 검증 또한 간단하다.

높은 성능을 내도록 병렬화가 되어 있는지 판단하는 것은 난해
* 코어 개수가 늘어날 때 병렬 프로그램이 좋은 확장성을 가지는가?
  * 메모리 대역폭 문제
  * 데이터 레이스 문제
* 가장 골치아픈 문제 로드 밸런싱 문제
  * 어떤 스레드만 바쁘게 일하고 다른 스레드는 놀 수 있다.
  * 이런 불균형을 잡는 것이 좋은 병렬 프로그램의 첫 번째 조건


멘델브로 프로그램에는 로드 밸런싱 문제가 있다.
* 행 단위로 분배
* 프랙털 이미지 중에는 복잡한 영역과 그렇지 않은 영역이 있다.
* 따라서 필연적으로 스레드 간 작업에 불균형이 야기된다.

OpenMP가 제공하는 스케줄링 기법
* parallel for 옆에 schedule이라는 키워드를 덧붙여 작업 분배를 동적으로 할 수 있다.
* 실시간으로 OpenMP 스케줄러가 작업을 스레드에 분배하는 것

워크 스틸링(work stealing) 기법
* 로드 밸런싱을 최적으로 맞춰주는 알고리즘
* 쉬는 스레드가 있으면 바쁘게 일하는 스레드의 일감을 훔쳐와 처리한다.
* 자체의 오버헤드가 있지만 일반적으로 가장 좋은 스케줄링 방법으로 알려져있다.

TBB(Thread Building Block)
* C++ 기반의 병렬 프로그래밍 라이브러리
* 스레드 생성과 소멸, 스케줄링 등을 태스크로 추상화하여 보다 쉬운 병렬 프로그래밍이 가능케 한다.
* 워크 스틸링을 이용한 스케줄링 또한 지원한다.

TBB를 이용한 멘델브로 프로그램
~~~C++
class ApplyMandelbrot
{
    int **my_p;

public:
    ApplyMandelbrot(int **p) : my_p(p) {}
    void operator() (const blocked_range<size_t> &range) const
    {
        for (size_t i = range.begin(); i != range.end(); ++i)
            for (int j = 0; j < max_col; ++i)
                my_p[i][j] = Mandelbrot(..., ...);
    }
};

void TBB_Mandelbrot(int **p)
{
    paralled_for(blocked_range<size_t>(0, max_row), ApplyMandelbrot(p), auto_partitioner());
}
~~~
* parallel_for : TBB에서 지원하는 기능
  * 루프의 순환 범위, 계산을 담당할 함수, 어떻게 작업을 분배할지를 인달로 전달
* ApplyMandel 클래스
  * 주어진 작업량을 수행
* auto_partitioner
  * 이것이 워크 스틸링에 해당
  * 스레드마다 작업량을 관찰하여 노는 스레드가 일감을 뺏어올 수 있게 한다.

## D. 데이터 병렬성을 활용하기
지금까지는 루프 병렬성을 활용해 병렬화
* 그런데 이 프로그램은 2차원 점마다 계산하는 작업이 모두 독립적
* 즉, 데이터 병렬성이 아주 많다.
* 병렬 계산 장치가 무한히 있다면 모든 점의 계산을 동시에 할 수 있다.


멘델브로 프로그램도 SIMD 벡터 연산으로 구현할 수 있다.
* 인텔에서 만든 Ct라는 스루풋 컴퓨팅을 위한 C언어 확장
* 데이터 병렬성을 쉽게 표현하여 병렬화하는 기법

~~~C++
Vec2D<I32> COUNT = 모두 0으로 초기화;
Vec2D<C64> Z     = 모두 0으로 초기화;
Vec2D<C64> C     = 초기 c 값으로 초기화;
Vec2D<Bool> DONE = 모두 0으로 초기화;
_for(int i = 0; i < max_count; ++i)
{
    DONE = abs(z) >= 2.0;
    COUNT = select(DONE, COUNT, COUNT+1);
    z = select(DONE, z, z*z + C)
}
~~~
* Vec2D는 2차원 벡터를 의미
* I32는 32비트 정수, C64는 64비트 복소수 형
* 각 점에 대해 초기값 c가 주어짐, c 값을 모두 모아 행렬 형태의 배열을 만든다.
* 나머지 계산에 필요한 Z, DONE 벡터, 결과 값을 저장할 COUNT 벡터
* 벡터 연산에 있어 분기문은 표현이 까다롭다.
  * Story 13의 프리디케이션 활용
  * _for 내부 스코프의 코드는 프리디케이션 형태로 표현한 것
  * DONE 벡터가 2.0보다 같거나 크면 더이상 count와 z값이 갱신되지 않는다.
  * select는 프리디케이션 역할을 한다.

select 연산의 의미
~~~C++
for (i = 0; i < N; ++i)
    COUNT[i] = DONE[i] ? COUNT[i] : COUNT[i] + 1;
~~~
* 멘델브로 함수는 데이터 병렬성이 풍부하므로 GPGPU에 적합 - Story 11


## E. MPI : 분산 메모리 환경을 위한 방법론
지금까지 알아본 모든 방법론은 주소 공간이 공유되는 SMP와 CMP를 위한 방법
* 주소 공간이 공유되므로 데이터 공유가 명시적인 전달 없이 그냥 메모리를 읽고 쓰는 것으로 해결

MPI(Message Passing Interface)
* 분산 메모리 구조를 위한 병렬 프로그래밍 방법론
* 명시적인 메시지를 주고받는 방식으로 데이터를 교환
* 네트워크를 통해 교환하는 것과 개념상 동일
* CUDA 프로그래밍과 유사
* 다만 이 과정을 추상화시켜 사용하기 쉽게 만든 것

지금은 그런데 MPI를 많이 사용하진 않는다.
* MPI는 다만 데이터를 직접적으로 교환하므로 동기화나 데이터 레이스 문제가 다소 덜하다.
* 그러나 데드락 같은 문제는 잘못된 통신함수 호출로 쉽게 겪을 수 있다.
* 프로그래밍 하기도 더 어렵다.

## 작성한 병렬 프로그램 검증하고 최적화하기
네 번째와 다섯 번째는 문제점을 찾고 프로파일링 및 최적화하는 단계
* 소프트웨어 도구의 힘을 빌어서 해야 한다.