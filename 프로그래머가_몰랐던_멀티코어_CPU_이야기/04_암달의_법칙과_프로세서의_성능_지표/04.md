# Story 04 암달의 법칙과 프로세서의 성능 지표
## 암달의 법칙
개선전 프로그램의 수행 시간이 1일 때
* foo() 함수의 실행 시간은 0.8, 최적화 후에는 0.4라고 할 때
* 나머지 0.2의 시간은 함수 최적화와 관련이 없다.
* 개선된 프로그램의 수행 시간은 0.6, 1과 비교하면 1.67배 성능이 향상되었다.

함수의 수행시간을 2배 빠르게 했지만, 프로그램의 성능은 두배가 되지 않음

암달의 법칙(Amdahl's law)
* 아무리 최적화를 하더라도 이 최적화로부터 영향을 받지 않는 다른 부분으로 그 효과는 제한적일 수 있다는 것

![a1](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/7823c05a-ce9f-473d-80da-30f757db68a6)
* 전체 중 P 부분이 S 만큼 개선될 때 기대되는 전체 성능 향상
* 이런 성능 향상을 스피드업(Speedup)이라 한다.

암달의 법칙이 주는 교훈
* 프로그래머가 프로그램 성능을 개선할 때 가장 많은 시간이 소요되는 곳에 집중하라
* Make the common case fast

## 병렬 처리에서 암달의 법칙
내가 만든 프로그램에서 80% 부분 병렬화 가능\
프로세서가 2개, 4개, 8개, N개일 때 성능은?
* 전체 수행 시간 1중 0.8을 프로세서 N개로 완벽히 병렬처리, 0.8/N
* 0.2는 여전히 직렬 수행

암달의 법칙, 병렬 프로그래밍 버전

![a2](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/8719ed85-8d26-43f7-8554-16a5867bd953)

암달의 법칙이 병렬화 문제에서 주는 과제
* 병렬화 가능한 부분의 극대화, 직렬로 처리해야 하는 (1-P) 부분을 줄이는 것이 핵심

암달의 법칙에는 제한이 많다.
* 직렬과 병렬 실행 가능한 부분이 혼재되어 있기 때문 (이를 나누기도 쉽지 않다.)
* 병렬성에 대한 구체적 설명없이 단순히 병렬 가능한 부분이 프로세서 수만큼 수행시간 줄어든다 가정
* 실제로는 이보다 성능 향상이 크게 안될 가능성이 있다.
  * 스레드 생성 비용, 뮤텍스 등 동기화 객체에 의해

별노력없이 병렬화 가능할 때, 이 작업을 "embarrassing parallel하다."라고 함

## 프로그램의 수행 시간
컴퓨터 속도를 정확하게 정의하면
1. 얼마나 빠르게 완료하는가 : 레이턴시(latancy)
2. 단위 시간당 얼마나 많이 처리하는가 : 처리율(throughput)

캐시는 대표적으로 레이턴시를 개선, 파이프라인은 처리율을 개선

명령어 완료 레이턴시만 생각
* 레이턴시는 응답 시간(Response time) 혹은 실행 시간(execution time)으로도 불린다.

T = N x Tinst
* T : 프로그램 전체 실행 시간
* N : 프로그램이 실행한 명령어 수
* Tinst : 명령어 하나를 처리하는데 걸린 평균 시간

현대 운영체제는 여러 프로그램이 작동 중이어서 공식이 정확히 맞지는 않는다.
* 충분히 큰 N이면 이정도 잡음은 무시 가능
* N과 Tinst만 안다면 프로그램 성능을 예측할 수 있다.

N, 실행한 명령어의 개수는 어떻게 구할까?
* 실제 동적으로 실행될 때의 개수
* 프로그램이 실제 입력 값으로 실행될 때 어떤 명령어가 실행되는지 트레이스(trace)를 뽑아야 한다.
* 보통 인스트루멘테이션(instrumentation) 기법으로 쉽게 구현

Tinst, 명령어 처리 평균 시간은 어떻게 구할까?
* 명령어 수행 시간은 제각각, 프로그램마다 명령어 분포도 다름
* 우리가 얻어야할 정보
  1. 어떤 종류의 명령어가 얼마나 많이 있는가? : 트레이서 분석
  2. 각각 명령어가 이 프로세서에서 수행될 때 평균 얼마나 걸리는가? : 실험적 추측
* Tinst의 단위는 (초/개)로 주어진다.
  * 클록 속도에 따라 다르므로 시간 대신 사이클을 이용하는 것이 편하다.


클록 속도를 고려해 고쳐쓴 수식

T = N x CPI x Tcycle
* CPI(Cycle Per Instruction) : 명령어당 평균 소요 사이클(사이클/개)

명령어당 처리 사이클이 종류에 따라 다름을 고려한 식

T = (∑Ni x CPIi) x Tcycle

물론 여기서 얻은 값은 예측값
* 전체적인 경향을 알아보거나 비교할 때는 유용하게 사용 가능

ISA가 같은 두 프로세서의 성능을 비교
* 동일한 벤치마크 프로그램, N 항은 같다.
* 클록도 같다면 결국 CPI만 비교해도 된다.

IPC(Instruction Per Cycle)을 CPI보다 더 많이 쓴다.
* CPI의 역수
* 최신 프로세서는 한 사이클에 1개 이상의 명령어를 완료하므로

MIPS 성능 단위
* IPS(Instruction Per Second)를 백만 단위로 표현

부동소수점 처리만 고려한 FLOPS(Floating Point Per Second)
* GPU 성능을 표현할 때는 GFLOPS, TFLOPS로 표현

MIPS의 맹점
* 단위 시간당 수행된 명령어 개수만 헤아리기 때문에 다른 ISA라면 결과 값이 다를 수 있다.
* 보통 이상적인 명령어 흐름에서 최고(Peak) 값을 사용

그러나 CPU, GPU의 연산 대역폭을 나타낼 때 유용하게 쓰인다.

## 성능 향상을 위해 해야할 일
위에서 살펴본 수식의 세가지 항을 생각
1. 실행한 명령어 개수 N
2. 명령어당 사이클 CPI
3. 클록 속도

## 명령어 개수 N을 줄이자
컴파일러의 최적화
* 불필요한 연산을 제거하거나 대체

대표적인 최적화
* 중복 수식 제거(Common Sub-expression Elimination)
* 상수 전파(Constant Propagation)
* 죽은 쓰기 제거(Dead Store Elimination)
* 최신 컴파일러의 부분 중복 제거(PRE, Partial Redundancy Elimination)

최적화를 통해 프로그램의 크기를 줄인다.
* 캐시 효율을 높이는 지름길

프로그램 크기가 작아진다고 항상 성능이 좋아지는 것은 아님

프로그램 크기는 늘지만 성능 향상을 위한 최적화
1. 인라인화(inlining)
   * 함수 호출 대신 코드를 그대로 붙여넣기
2. 루프 풀기(loop unrolling)
   * 분기문의 횟수를 줄여 파이프라인 효율을 높이고 루프 탈출 비교 횟수 자체도 줄일 수 있다.

이런 최적화는 트레이드오프(tradeoff) 관계로 최적점을 찾기 힘들다.

하드웨어 발전 속도는 눈부시게 빠르지만, 컴파일러 기술은 그에 비해 더디다.
* 컴파일러의 성능 향상은 18년 마다 2배, 년 3.9%

## CPI를 줄이자.
RISC와 CISC에 대한 고려
* RISC는 CPI는 낮지만 N이 많다.
* CISC는 외부적으로 N이 작고 CPI는 크게 보이지만, 마이크로옵(uop)을 고려해야 한다.

CPI는 마이크로아키텍처에 큰 영향을 받는다.
* 장치(캐시 등)을 개선하여 CPI를 줄일 수 있다.
* 파이프라인, 슈퍼스케일러, 비순차 실행, 분기 예측, 투기적 실행 등이 CPI를 낮추는 기법

## 클록 속도는 빠르게
클록 속도에 영향을 주는 요소는 다양하다.

반도체 제조 기술
* 회로의 기본 폭을 낮춘다. 더 많은 트랜지스터 집적
* 제조 공정 미세화를 통해 캐시 용량을 늘릴 수 있다.
* 클록 속도 역시 미세 공정으로 빨라질 수 있다.

클록을 결정짓는 요소 : 한 사이클에 완료 되어야 하는 일의 양
* 일의 양을 줄이면 클록 속도를 높일 수 있다.

현재의 기술로는 한계에 다다른 상황이다.



