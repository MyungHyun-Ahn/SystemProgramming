# Story 15 효율적인 메모리 명령 실행 알고리즘

## 효율적인 메모리 연산의 실행
현대 프로세서와 그래픽 프로세서의 성능은 결국 메인 메모리 성능에 달렸다.
* 메모리 레이턴시와 메모리 대역폭 모두 성능을 결정적으로 좌우
* 멀티코어 구조에서 더욱더 메모리 성능이 중요해졌다.

캐시가 중요한 이유
* 긴 메모리 레이턴시를 조금이나마 극복하고자 함

고성능 비순차 프로세서 이야기를 하며 빠뜨린 것
* 메모리 로드/스토어 실행에 관한 이야기
* 간단히 메모리 로드/스토어는 인자로 받은 주소 값을 구해 데이터를 읽거나 쓰면 된다.

### 메모리 연산이 어떻게 비순차 프로세서에서 처리될까?
비순차 프로세서, 분기 예측 기반의 투기적 실행이 지원되는 프로세서
* 명령어가 완료(commit, retirement)된다는 것은 반드시 자신이 비투기적인(non-speculative) 상태임을 뜻한다.
* 쉽게 표현하면 명령어가 반드시 확실하게 판명이 난 분기문의 흐름에 있어야 한다.
  * 만약 불확실한 예측 기반의 분기문 흐름이 있다면
  * 예측 실패로 무효화 가능성 있음 - 메모리나 레지스터에 반영하면 안됨
  * 이 값을 ROB(리오더 버퍼)나 다른 버퍼에 가지고 있다.
  * 마지막으로 완료되어야 실제 메모리를 읽고 쓴다.

위 사실을 염두에 두며 메모리 로드/스토어의 비순차 실행에 대해 알아보자
* 메모리 연산은 메모리 의존성을 띠고 있다.
  * 레지스터 이름으로는 의존성 파악 불가
  * 실제 주소 값을 알아야 의존성을 알 수 있다.

어떻게 메모리 로드/스토어를 비순차적으로 실행하여 메모리 레이턴시를 줄일까?

메모리 의존성 예
~~~c++
1 (0x100):  load    r3 = 0[r6]      ; r3 = *r6
2 (0x104):  add     r7 = r3 + r9    ;
3 (0x108):  store   r4 = 4[r7]      ; *(r7 + 4) = r4
4 (0x10C):  sub     r1 = r1 - r2    ;
5 (0x110):  load    r8 = 4[r1]      ; r8 = *(r1 + 4);
~~~
* 1, 2, 3 명령 : 각각 레지스터 r3와 r7으로 RAW 의존성이 있어 순차 실행되어야 한다.
* 4, 5 명령 : 레지스터 r1으로 순서대로 처리되어야 한다.
* 그러나 {1, 2, 3}, {4, 5} 그룹은 서로 독립적으로 실행될 수 있는 것처럼 보인다.
  * 명시적인 데이터 의존성이 안 보인다.
  * 그렇지만 명령 3, 5번의 메모리 로드/스토어를 살펴봐야 한다.
  * 의존성이 있을수도 있음
* 만일 2, 4번 명령어의 연산 결과가 같아 r1과 r7의 값이 같다면
  * 3, 5번 메모리 명령은 각각 같은 메모리 주소에 쓰고 읽는다.
  * 반드시 이 경우에는 뒤따르는 읽기는 반드시 쓰기가 끝나고 수행되어야 한다.
  * RAW 의존성과 같다.
* r1과 r7의 값이 다르다면
  * 3, 5번의 메모리 연산은 아무런 관련이 없어서 비순차로 실행될 수 있다.

메모리 의존성은 명령어 해독만으로 파악할 수 없고 반드시 주소 값을 구해야 한다.
* 가장 쉬운 해결법은 비순차 실행을 포기하면 정확하게 명령을 실행할 수 있다.

그런데 일반적인 x86 프로그램은 코드 중 38%가 메모리 연산
* 이 중에는 비순차적으로 실행 가능한 메모리 연산이 많다.
* 무조건 순차적으로 실행해야 한다면 치명적
* 어떻게든 비순차적으로 실행할 수 있도록 만들어야 한다.

## 로드 스토어 큐
효율적인 메모리 연산의 첫 번째 목표
* 메모리 연산 중 메모리 의존성이 확실히 없는 것에 대해 비순차 실행을 허용하는 것

메모리 의존성
* 같은 메모리 주소에 대해 현재 수행 중인 메모리 스토어가 모두 완료되어야 그 주소에 대한 뒤따르는 메모리 로드를 할 수 있음을 의미

로드 스토어 큐(Load Store Queue, LSQ)
* 의존성을 파악하기 위해 파이프라인 내 명령어 중 메모리 연산만 관리하는 자료구조
* LSQ는 현재 수행 중인 메모리 연산의 내용을 간직하여 메모리 의존성을 검사한다.
* 메모리 의존성이 없다는 것이 밝혀지면 비순차 수행을 허용한다.
* LSQ는 메모리 명확화(disambiguation) 문제를 푸는 장치

메모리 명확화 문제
* 같은 주소에 대해 나보다 앞선 완료되지 않은 메모리 스토어 명령이 있는지 살펴보는 것

위 소스가 LSQ에서 어떻게 작동할까?
* 3, 5번 메모리 스토어와 로드를 주목하여 설명
* 이 둘의 관계는 세 가지로 설명 가능
  1. 주소가 서로 같음
  2. 주소가 서로 다름
  3. 아직 모름

LSQ의 대략적인 형태

![14-01](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/4e4e8661-cd85-47a4-b753-836ab9f543dc)

기록되는 요소
* 엔트리마다 순번(새로운 명령어일수록 큰 값)
* 로드/스토어 여부
* PC
* 데이터 주소
* 데이터 값

LSQ에 이 명령이 있다는 것 : 아직 파이프라인에서 완료되지 않았음
* 메모리 연산이 완료될 수 있다면 LSQ의 내용을 직접 메모리에 반영

위 표는 소스의 세 메모리 연산을 담고 있는 LSQ의 모습
* 0x108의 스토어와 0x110의 로드가 같은 주소를 가리키는 경우
* 프로세서가 0x110 로드를 실행할 때 메모리 의존성을 가지는 명령이 있는지 LSQ를 뒤져야 한다.
* 결과, 앞선 스토어 중 하나의 주소값이 동일한 것을 확인
* 0x110 로드는 무조건 0x108 스토어의 결과를 기다려야 한다.
* 0x108 명령이 완료되고 80이라는 값을 받아왔다.
* 스토어가 완료된 것은 아니므로 데이터 캐시 주소의 값은 최신 값이 아니따.
* 따라서 0x110 로드는 LSQ에서 값을 얻어와야 한다.
  * 이 과정을 Store-to-Load Forwarding이라 한다.


0x108의 스토어와 0x110의 로드가 다른 주소를 가리킬 때
* 두 연산의 상관없이 데이터 캐시를 읽을 수 있다.
* 비순차 실행이 가능

0x108 스토어의 주소 값이 0x110 로드를 실행할 때까지도 알려지지 않았을 때
* 보수적으로 무조건 메모리 의존성을 가정

## 메모리 의존성 예측기와 또 다른 투기적 실행
메모리 로드는 최대한 앞당겨 실행시키는 것이 중요
* 캐시 미스가 있더라도 손해를 감출 수 있다.
* 앞에서 설명한 것으로는 부족
* 좀 더 적극적인 방법이 존재한다.

예측기를 이용하는 것
* 분기문과 비슷하다.
* 예측에 기반된 실행 - 투기적(speculation) 실행
* 만약 예측이 틀렸다면 메모리 로드와 의존적인 명령어를 제거하고
* 다시 해당 명령어부터 다시 실행

이러한 메모리 의존성 예측기가 잘 작동할 수 있는 이유
* 어떤 메모리 로드가 자신보다 앞선 메모리 스토어와 충돌을 일으킨 전력이 없다면 앞으로도 그러지 않을 것이라는 관찰에 근거
* 프로그램에 어떤 로드와 이보다 앞선 가까운 스토어는 서로 다른 메모리 주소를 가리키는 것이 흔하다.
  * 같은 주소에 값을 쓰고 바로 읽는 코드는 흔하지 않다.
  * 최적화된 코드에서는 흔한 것이 아니다.

인텔 Core 마이크로아키텍처에 적용된 메모리 의존성 예측기의 작동 방식
* 분기 예측기나 캐시 처럼 PC 주소를 입력받는 해시 테이블 구조
* PC 주소와 혹은 히스토리 정보를 조합해 이 예측기의 엔트리에 접근
  * 각 엔트리는 카운터 값을 가지고 있다. - 한계 값이 있다.
  * 메모리 로드가 완료되는 시점에 갱신된다.

카운터는 다음과 같은 규칙을 따른다.
1. 만일 로드가 잘 작동했다면, 즉 주소가 밝혀지지 않은 스토어와 충돌하지 않았다면 카운터 값이 증가한다.
2. 만일 로드가 적어도 하나라도 앞선 스토어와 충돌을 일으켰다면 카운터를 0으로 초기화한다.
   * 단, 이 스토어는 로드보다 코드상으로 앞에 있지만 실제로는 이 로드 후에 실행이 시작된 것만 해당한다.

메모리 의존성 예측기는 로드 명령어가 실행되기 시작할 때 사용된다.
* 만일 로드에 해당하는 예측기 엔트리의 카운터 값이 최대라면 '안전하다'라고 예측, LSQ 엔트리에 기록
  * 이제 자신보다 앞선 스토어 중 주소가 아직 알려지지 않은 것이 있어도 계속 실행
* 카운터 값이 최대가 아니라면 일반적인 방법
  * 알려지지 않은 스토어 주소가 있으면 대기
  * 틀렸을 때 다시 실행하는 장치가 필요하다.
* 만일 예측 적중률이 어느 수준 이하로 떨어지면
  * 예측 자체를 중단

## 컴파일러 최적화의 장애물 : 포인터
메모리 명확화 문제는 프로세서에만 있는 것이 아니다.
* 컴파일러도 이 문제로 최적화가 어렵다.

포인터로 인한 메모리 의존성
~~~C++
*x = *y + 1;
*a = *b + 2;
~~~
* 포인터만 봐서는 데이터 의존성 여부를 알 수 없다.
* 직접 실행해야 알 수 있다.

두 포인터가 서로 겹치는 일이 있는지 없는지 따지는 문제
* 포인터 분석 혹은 앨리어스 분석이라 한다.
* 지금까지도 수많은 연구가 계속되고 있다.

포인터는 C/C++의 가장 큰 장점
* 그러나 많은 버그의 원인이 되므로 약점이기도 하다.
* C/C++ 컴파일러의 최대 최적화 장애물

컴파일러의 최적화
* 쓸데없는 코드 제거, 중복된 계산식 축약, 인라인 등등
* 메모리 레이턴시 줄이기, 순서 뒤집기 등등 강력한 최적화
* 이런 최적화의 기본은 명령어 사이의 의존성 분석
  * 그런데 포인터가 끼어들면 의존성 분석이 어려워진다.
  * 고급 최적화에 방해
* 포인터가 들어간 코드는 대부분 보수적인 최적화만 진행한다.

C언어는 C99에서 최적화 문제에 도움을 주고자 restrict 키워드를 C99에 도입했다.
* 함수 인자의 포인터 변수가 겹치지 않는다면 restrict 키워드를 추가하여 컴파일러가 더 많은 최적화를 하도록 한다.

만약 포인터가 모두 다른 영역을 가리키는 것을 안다면
* 루프 풀기 혹은 SIMD 연산으로 대체하는 자동 벡터화를 할 수 있다.

자동 병렬화(automatic parallelization)
* 컴파일러가 수행하는 가장 고급 최적화 중 하나
* 벡터 합 코드에서 N이 매우 크다면 자동으로 병렬화 할 수 있다.
* 그런데 C/C++에서는 간단한 코드 조차 포인터 문제로 실패한다.

동적할당 2차원 배열 2개
* 두 배열 사이에 의존성이 없음을 밝혀야 자동 병렬화가 가능하다.
* 그러나 포인터 분석의 어려움으로 의존성을 가정하고 포기한다.
* doulbe L[1024][1024]와 같이 할당하면 이 코드는 자동 병렬화가 된다.