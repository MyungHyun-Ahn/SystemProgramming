# Story 07 고성능 프로세서의 시작 : 명령어 파이프라인

## 파이프라인의 기본 개념
파이프라인(pipeline) 소개
* 마이크로프로세서의 성능이 비약적으로 높아지는데 기여한 가장 핵심적인 기술
* 가장 핵심적인 파이프라인 : 명령어 파이프라인
* 산술 연산 장치 등 어느 정도 시간이 걸리는 주요 작업은 파이프라인화(pipelining) 되어있다.

파이프라인이란?
* 연속으로 주어진 어떤 작업을 처리하는 데 있어 처리율(throughput)을 높이는 일반적인 알고리즘
* 파이프라인 알고리즘의 핵심은 재사용과 병렬 실행

### 파이프라인화
* 작업을 여러 세부 단계로 나눈다.
* 먼저 시작된 작업이 다음 단계로 가면, 다음 작업을 받아 수행
* 처리율, 단위 시간 당 처리할 수 있는 일의 양을 크게 높일 수 있다.

세탁과정에 비유한 파이프라인화

![7-01](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/228b8e51-4eb4-4d7a-bad8-113d39469125)


![7-02](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/e6b98061-5708-4ae2-93b7-5a3a73463b02)

위 그림의 절약된 시간을 일반화하면
* 작업 N개 파이프라인 X -> N 시간
* 작업 N개 파이프라인 2개 -> (N-1) / 2 + 1
* 작업 N개 파이프라인 a개 -> (N-1) / a + 1
* N이 만약 충분히 크다면 처리율은 a 배 올라간다.

즉, 파이프라인으로 얻는 이상적인 처리율 증가(speedup)는 파이프라인 단계 수 만큼 된다.
* 그러나 레이턴시는 개선할 수 없다.
* 한 개의 작업을 더욱 빨리 처리할 수는 없다.

## 파이프라인의 효율적인 설계
파이프라인이 이상적인 k 배의 처리율을 얻기 위한 조건
1. 균등한 파이프라인 단계 : 각 단계는 균등한 길이
2. 같은 작업 : 항상 같은 작업만 수행
3. 독립적인 작업 : 투입되는 작업은 서로 의존 관계 없음
4. 파이프라인 유지 비용의 최소화 : 최적의 파이프라인 깊이

### 균등한 파이프라인 단계
* 파이프라인의 효율은 각 단계 중 가장 느린 단계가 결정

파이프라인 단계를 7분, 7분, 16분, 30분처럼 비대칭으로 나누자.

![7-03](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/da349473-e1e9-46c2-87b2-5be7e2f00487)
* 가장 느린 30분 단계가 성능을 결정
* 중간에 작업이 멈추는 시간이 발생 : 파이프라인 스톨(pipeline stall)

따라서 최대한 작업 단계가 비슷한 시간이 되게 설계해야 한다.
* 현실적으로는 힘들다.

### 같은 작업
* 이상적인 파이프라인은 처리하는 작업이 모두 동등하다.

처리하는 작업의 독립성
* 작업간의 의존성이 없어야 차례대로 기다림 없이 진행할 수 있다.
* 실제로는 지켜지기 힘들다.

![7-04](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/464d7d8c-4a4b-4881-86dc-188244e3cedf)
* 이전 작업의 결과에 따라 다음 작업이 진행되어야 하는 상황
* 이전 작업이 끝날 때까지 기다리므로 파이프라인 스톨 발생
* 가장 중요한 문제 중 하나 - 해결 방법 곧 알아봄

### 파이프라인 자체의 비용
파이프라인의 단계가 너무 많아지면?
* 처리율 이득을 상쇄시킬만한 이동 비용이 발생할 수 있다.
* 즉, 레이턴시의 큰 손해를 본다. 

파이프라인 깊이(pipeline depth)
* 파이프 라인이 k단계로 나뉘어 있을 때의 k값
* 너무 깊은 파이프라인은 피해야 한다.
* 채우는데 비우는데 시간이 걸리기 때문

## 파이프라인 프로세서의 구현
명령어 처리율을 높이는 근본 원리 : 병렬 처리
* 이를 위해 먼저 동시에 처리할 수 있는 명령어(병렬성)들을 찾아야 한다.
* 효과적인 하드웨어 자원도 제공되어야 한다. (멀티코어)

멀티 코어가 병렬처리에 이상적인 이유
* 여러 스레드의 명령어는 서로 독립적
* 일부 캐시를 제외, 프로세서 자원을 복제한다.

과거에는 기술이 좋지 못했다.
* 파이프라인은 하드웨어 복제를 조금 하면서 명령어 처리율을 높이는 최초의 병렬 기술로 볼 수 있다.

프로세서는 여러 장치에 파이프라인을 적용
* 대표적으로 명령어 파이프라인(instruction pipeline)

### 명령어 파이프라인
* Story 06에서 본 명령어 사이클을 파이프라인에 적용시킨 것
* 제약 조건 : 한 단계는 한 사이클 이내 완료되어야 한다.
* 사이클마다 파이프라인 단계 진행

따라서 가장 긴 파이프라인 단계가 클록속도 결정
* 5단계 명령어 파이프라인 -> 레이턴시 5사이클
* 명령어 처리율은 클록 당 1개

그러나 이런 것은 잘 지켜지지 않는다.

## 파이프라인의 단편화를 줄이자
이상적인 파이프라인 조건
* 균등한 파이프라인
* 같은 작업이 투입

지켜지기 어려운 이유
* 명령어는 ALU 명령어, 로드, 스토어, 분기문 등 각 명령어의 작업이 다르다.
* ISA 특이성, 실제 프로세서 구현 제약 고려

실제로 균형을 맞추는 방법
* 단계를 합치거나 나누어 균형을 맞춘다.
* 서로 다른 작업도 최대한 같은 부분을 찾아 통합한다.

### 내부 단편화 문제(internal fragmentation)

파이프라인의 내부 단편화

![7-05](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/aa1993a5-e292-43e2-92bb-73f750a51f54)

명령어 인출(IF)과 해독(ID) 단계
* RISC 구조 : 명령어 인출과 해독은 간단해 합칠 수 있다.
* x86 CISC : 상당히 복잡하다. - 이 과정을 나누어 파이프라인 균형을 맞춘다.

피연산자 인출(OF) 단계
* 우리가 정의한 단계 : 레지스터 읽기, 메모리 읽기 작업 포함
* 레지스터 읽기는 빠르지만 메모리 읽기는 느리다.
* 실제 구현에서는 이를 구분한 단계로 처리한다.

실행(EXE) 단계
* 서로 다른 연산(처리시간도 당연히 다르다)을 같은 단계에서 처리하는 것은 비효율적
* 따라서 별도의 파이프라인 단계를 가지는 것이 합당

이런 서로 다른 파이프라인 단계에 의해 스톨이 발생할 수 있다.

### 외부 단편화(external fragmentation) 문제
파이프라인의 외부 단편화

![7-06](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/a5ea00f1-a4e0-426b-9be8-2cb81b79f087)

* 어떤 명령어는 어떤 단계를 필요로 하지 않기 때문에 발생
* 다른 명령어가 중간을 차지하고 있어 명령 수행 불가
  * 구조 해저드(structural hazards) : 자원 부족으로 겪는 현상

### 최적 파이프라인 깊이
파이프라인 깊이가 곧 프로세서의 클록 속도를 결정한다.
* 이것은 곧 깊이가 성능에 큰 영향을 미친다는 것

파이프라인의 이상적인 처리율 상승은 파이프라인 깊이에 비례
* 더불어 클록 속도 또한 높일 수 있다.

파이프라인의 한 단계 -> 한 사이클
* 이걸 더 잘게 쪼개면 일의 양이 줄기 때문에 빠른 클록

현대 프로세서는 보통 10단계 이상의 깊은 파이프라인을 채용
* 파이프라인이 약 50단계가 되면 아무리 클록 속도가 빨라져도 시스템 성능은 하락 (Story 10)

## 파이프라인 해저드

파이프라인 해저드(hazard)
* 파이프라인 프로세서에서 의존성으로 발생할 수 있는 문제를 칭함
* 가장 간단한 해결책 : 파이프라인을 멈추는 것(Stall)
  * 이건 별로 원하는 해답이 아니다.

해저드의 종류
* 구조 해저드
* 데이터 해저드
* 컨트롤 해저드

각 해저드를 어떻게 해결하는지 알아보자

파이프라인 해저드는 전적으로 파이프라인 구성에 달렸다.

### 구조 해저드
구조 해저드(structural hazard)란?
* 프로세서의 자원이 부족해서 발생하는 스톨을 말한다.

해결책은?
* 자원을 그만큼 늘리면 된다.

파이프라인화할 때 필요한 컴포넌트의 추가 비용을 생각
* 레지스터 파일과 메모리 장치는 구조 해저드를 발생시키지 않게 업그레이드
* 파이프라인이 k단계라면 최대 k개 명령어가 프로세서의 각각 다른 파이프라인에서 처리
* 최악의 경우, 파이프라인이 스톨없이 동작하려면 각 장치들이 최대 k개의 명령어를 감당할 수 있어야 한다.

레지스터 파일을 생각
* ALU 명령어는 2개의 피연산자를 레지스터 파일에서 읽고 최종 결과 1개를 쓴다.
* 파이프라인 프로세서에서는 OF 단계 명령어와 OS/WB 명령어가 동시에 작동
* 따라서 레지스터 파일에서는 2개의 읽기와 1번의 쓰기가 동시에 작동해야 한다.

그러나 멀티포트화(많은 읽기 쓰기 동시에)는 어렵다.
* 아주 큰 레지스터 파일이나 캐시에 많은 수의 읽기/쓰기 포트를 두는 것보다
* 적은 수의 읽기/쓰기 포트를 가진 작은 컴포넌트를 여러개 두는 방법을 택한다.

컴포넌트의 단위
* 캐시 : 뱅크(bank)
* 레지스터 파일 : 클러스터(cluster)

## 컨트롤 해저드
컨트롤/데이터 해저드
* 프로그램이 근본적으로 가지는 의존성 때문에 발생

명령어 인출 단계에서는 PC가 가리키는 주소에서 명령어를 읽는다.
* 다음 PC를 구하기는 분기문 때문에 쉽지 않다.

~~~C++
1: if (z > 0) goto 4;
2: a = 1;
3: goto 5;
4: a = 0;
5: x = y + z; // 1~4와는 무관한 명령
~~~
* 1번 분기문을 구하지 않으면 2, 4번 명령 중 어떤 것을 인출할지 모른다.
* 즉, 파이프라인은 분기문의 결과가 나올 때까지 기다려야 한다.

책 기준으로 EXE 단계 이후 결과를 확인하고 다음 단계가 진행

![7-07](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/f43df16a-736f-4a18-a7b8-fe00c84109d4)

* 3 사이클을 손해
* 분기문은 매우 자주 나오는 명령어로 치명적이다.

조금이나마 줄이려면 분기문의 계산을 OF 단계에서 한다.
* 이렇게 해도 스톨은 1개 밖에 줄일 수 없다.

![7-08](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/ae18ac08-a354-4852-8e3a-05fe59ed1779)

위 그림처럼 컨트롤 의존성 관계에 있는 명령 사이에 무관한 명령을 넣을 수 있다.
* 명령어 재배치 : 컴파일러가 수행
* 위 예에서는 명령 5가 마지막이므로 남는 곳에는 NOP(No Operation)을 넣었다.
* 지연 슬롯(delayed slot) 기법 : MIPS 프로세서에서 제공

지연 슬롯은 완벽하지 않다.
* 지연 슬롯의 명령어는 의도한 순서와 다르게 완료
* 완벽히 슬롯을 제거할 수는 없다.

그래서 나온 기법 - 분기 예측(branch prediction)
* 미리 분기문의 결과를 예측하는 것
* 예측이 옳다면 큰 성능 향상 - 전혀 스톨이 발생하지 않는다.
* 그러나 분기 예측이 실패하면 파이프라인을 비우고 다시 진행 (Story 13, 14)

## 데이터 해저드
RAW / WAW / WAR 데이터 의존성과 메모리 의존성으로 발생

파이프라인 단계를 다듬어보자.
* 파이프라인 해저드는 파이프라인 구성에 따라 모습이 다르다.
* 앞에서 가정한 파이프라인 구조에서는 OF 단계가 지나치게 단순하다.
* 레지스터 읽기와 메모리 읽기를 분리하여 6단계의 파이프라인 단계를 구성하자

![7-09](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/7e7e08b9-01e3-4e6e-aec2-ed31c1f31ccf)

* 모든 연산 종류가 이 과정을 거치는 것은 아니다.
* 명령어마다 파이프라인 단계가 다르고 의미도 차이난다.

RAW 해저드를 설명하는 기계어
~~~C++
1: r1 = r2 + 1; // r1 ~ r5는 레지스터를 뜩한다.
2: r3 = r1 + 1; // 레지스터 r1에 의해 RAW 의존성
3: r4 = r1 + 2; // 레지스터 r1에 의해 RAW 의존성
4: r5 = r1 + 3; // 레지스터 r1에 의해 RAW 의존성
~~~
2, 3, 4 명령은 명령어 1의 WB를 기다려야 한다.
* 3 사이클 대기

![7-10](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/4c4d427a-3447-461c-80e9-1dee81cb36e6)


명령 2가 명령 1이 WB를 마칠 때까지 기다릴 필요는 없다.
* 명령 1이 ALU 단계에서 바로 결과를 명령 2로 전달
* 바이패스(bypass, 우회로) 기법
* 데이터 해저드를 해결하는 중요한 장치

![7-11](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/42670065-3bb8-4f81-a1ea-919385a257fb)

바이패스는 여러 단계에서 작동할 수 있다.
* 명령 1과 명령 2는 ALU 단계에서 해결
* 명령 3, 4는 왜 그렇지 않은가?
* 2~3 사이클 간격이 있다 -> 별도의 버퍼를 두어 저장하기에는 어려움
* 바로 다음 파이프라인 단계로 임시 결과를 전하는 것이 용이

바이패스 로직은 루프를 만든다.

![7-12](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/7e54d291-5fc0-4162-8eb2-a6107843384a)

* 데이터 흐름은 루프를 그리며 뒤따르는 명령에 피드백

백투백(Back-to-Back) 의존성을 가진 명령어
* 명령어들이 뒤따르며 RAW 해저드를 기잔 명령어
* 백투백 명령어가 스톨없이 처리되도록 파이프라인 단계외 바이패스 로직을 만들어야 한다.

WAW / WAR 의존성은 지금 구조에서는 해저드를 만들지 않는다.
* 모든 명령어가 순서대로 처리
* WAW / WAR 명령어 사이에서 최종 결과를 쓰는 작업은 항상 마지막 단계

메모리 로드로 인한 RAW 의존성 - 로드-유스(Load-Use) 데이터 해저드

![7-13](https://github.com/MyungHyun-Ahn/SystemProgramming/assets/78206106/18a1d747-6465-4254-a1c3-b6082bc3c3cc)

* 메모리 로드는 MEM 단계가 되어야 값을 얻어올 수 있다.
* 뒤따르는 명령에서는 ALU 단계에 값이 필요하다.
* 어쩔 수 없이 우리의 구조에서는 하나의 스톨 발생
* 실제 고성능 프로세서는 이것도 제거한다.

## 파이프라인 : 소프트웨어 병렬화의 한 가지 방법
파이프라인은 소프트웨어 디자인 패턴으로 활용될 수 있다.

직렬 버전의 프로그램
~~~C++
void scan(void)
{
  while(true)
    do_query();
}

void do_query(void)
{
  단계1();

  단계2();

  단계3();

  ...
}
~~~
* 디렉터리의 이미지를 탐색하는 프로그램
* 병렬화 한다면?
* 순서를 지켜야 한다면 scan() 함수를 쉽게 병렬화 불가능
* 구역을 나누고 여러 스레드가 scan() 호출

그러나 이 방법은 문제가 있다.
* 하드디스크나 데이터베이스가 병목 지점이 된다.
* 하드디스크에서 병렬로 데이터를 읽을 수 없다면 병렬화의 의미가 사라짐

scan() 함수 말고 do_query() 자체를 병렬화
* 단계1,2,3은 파이프라인 단계와 닮아 있다.
* 스레드를 함수 개수만큼 만들고 각 단계를 수행시킨다.
* 스레드 사이에는 데이터가 흐른다. -> 공유 큐(동기화 객체 혹은 락-프리로 동기화)

프로세서의 파이프라인과 마찬가지로
* 조건, 여러 설계 변수의 고민 또한 파이프라인 병렬 프로그래밍 기법에도 적용된다.
* 소프트웨어 파이프라이닝(Software Pipelining) 이라는 별도의 기법 존재
* VLIW(Story 17) 같은 구조에서 최대한 명령어를 동시실행하도록 재배치하는 알고리즘이다.

명령창에서 '|'로 표현되는 파이프로 여러 연결 프로그램을 연결하면 강력한 작업 가능
* 이것도 파이프라인과 같다.
* ps -aux | grep root | wc -1
* 처음 명령의 흐름이 다음 명령의 입력으로 흐른다
* 여기서 파이프로 연결된 명령이 충분히 오랜 시간 동작하면 파이프라인 병렬화처럼 작동한다.